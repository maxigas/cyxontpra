-   Introduction
    -   The case for deep hacker studies
-   Figurations of cybernetics in the European hacker tradition
-   Practices favouring practice
    -   Exploratory programming
    -   Penetration testing
    -   Hardware hacking
-   Odd institutions hosting strange performances
-   From cybernetic ontologies to hacker ethics
-   Conclusion
    -   Anti-modern techno-science society
    -   Cybernetics vs. hackerdom
    -   Summary

Introduction
============

The case for deep hacker studies
--------------------------------

Hacker artefacts, knowledges, practices and scenes constitute an alternative engineering culture that can be characterised as anti-modern techno-science. Constructed in the wake of the 1960s cultural shock (Wallerstein, 2004: 16), hackers’ attitude to technology is reminiscent of the cybernetic ontology identified by Pickering (2010) and articulated in the sciences by cyberneticians. It privileges practice over representation, performance over cognition, and adaptive encounters with the unknown over the domination of Nature. In short, it is informed and forged by an experience in the ontology of becoming.

While it has been demonstrated that even engineers and scientists working in the heart of modern institutions grapple with the mangle of practice in their daily routines (Pickering, 1995), it has also been pointed out that neither official accounts of engineering or scientific work, nor the institutions that frame them are necessarily constructed according to such realisations. Simply put, the role of material agency in techno-scientific research is not taken into account adequately by modern institutional frameworks. Pickering (2010) brought a historiography of scientists – the cyberneticians – who attempted to reformulate scientific tools, theories, practices and institutions to match their experiences in the ontology of becoming. Starting from the figurations of cybernetics in European experiences of hacking, I argue here that an anti-modern techno-science can be shown to be at work in our contemporary historical horizon. Some hacker practices do more than dealing with the contingencies of material resistance found everywhere in research: these practices are designed to invite such encounters and encourage resistance to shape processes and results. Furthermore, organisational forms of hackers take seriously such encounters rather than incorporating them to fit institutional expectations. Once again, rather than claiming that hackers work with an ontologically different technology than mainstream engineers, what I seek to demonstrate is that *ontology matters* as part of culture.

Pickering shows that the classic cyberneticians’ non-modern approach was so transversal that it did not fit into the grid of modern institutions, and therefore they failed to reproduce their social basis. What I intend to point out is that hackers’ practices are articulated in opposition to best practices in the academic-military-industrial complex to the point where they set up their own organisational infrastructures to sustain their scenes and reproduce their social basis. In a more nuanced analysis below, I seek to capture the difference between how hackers and how cyberneticians enact a cybernetic ontology in the contrast between *non-modern* and *anti-modern* techno-science.

As Pickering when researching English cyberneticians, I am more interested in how to live and how to engineer in a different way, than to capture the essence or the statistical veracity of hackerdom. The wealth of the empirical material is drawn from the European hacker tradition, but I do not claim that it represents the mainstream of hacking there or elsewhere. I would rather like to chart an undercurrent of motifs that is theoretically revealing. Everything that is laid down here is taken from my decade long anthropological and historical research into hackerspaces, but this time the ambition is not ethnological documentation.[1] Studying hackers offers lessons on how artefacts, knowledges, practices and even organisations can be different when the mangle of practice is taken into account in a more consistent and coherent manner.

Asking such questions is essential in a historical moment when late modernity seem to have exhausted its potential, so that we have to look at other ways of dealing with the world in order to find adequate responses to social, environmental, economical, political and institutional crises. While hackers’ encounters with the unknown are certainly not enough to address these issues, they may possibly offer lessons about alternative pathways to take. After all, as Pickering phrases it, alternative engineering cultures can be seen as a “collective exploration of the nonmodern selfhood”, where new subjects in conjunction with new artefacts and, in tandem, new kinds of “odd institutions” are constructed (Pickering, 2010: 200, 400). The advantage of inquiring into hacker culture rather than cyberneticians is that it is possible to analyse collective practices rather than individual contributions, and ones that are formative of our current historical horizon. *Notwithstanding the “social marginality” of hackers and the “hobbyist origins” of hacking (Pickering, 2010 about cybernetics, 388), in the penultimate section I argue that hacker practices ground an anti-modern ethical relation to material agency framed by a symmetric ontology.* However, first it is necessary to situate hacker practices historically in relation to the cybernetics movement.

![Logo of the Brussels Hackerspace](images/hsbxl-logo.png)

Figurations of cybernetics in the European hacker tradition
===========================================================

Ross (1990) identifies a shift in the expression of countercultural dissent in the decades following the 1960s. He describes the ecologically-inspired anti-technology attitude of the hippies as the *technology of folklore*, contrasting it with the *folklore of technology* that inspired cyberculture – revolving around perseverance in a dystopian and oppressive world through technological expertise. He does acknowledge that it is harder to read such new dissent politically. Developing these doubts, Markoff (2005) and Turner (2006) focus on the cross-breeding of counterculturalists in decline and the ascendant Silicon Valley entrepreneurship – what Barbrook and Cameron (1996) called the *Californian ideology* or what Curtis (2011) blames directly on cybernetics.

Reactionary or not, as Leary (1994) vividly expresses, the translation happened through novel artefacts, knowledges and practices of the brain, which in pop culture meant mainly psychedelics. Essentially, subjects became hollow objects to be crudely manipulated in a determinist fashion, while objects expressed a richer subjectivity in their non-determinism. *Cyberpunk* – first as a sub-genre of science fiction and soon as a fully fledged subcultural phenomena – expressed such ontological ambiguity in the language of the gothic uncanny (Cavallaro, 2000; Grant, 1998; Rapatzikou, 2004; Whatley, 2014). Despite the dystopian bent of cyberpunk imaginaries, hackers drew the conclusion that in case the underdogs can grasp new technologies faster than the powers that be, they can at least go out with a bang.[2]

As the “cyber-” prefix suggests, these advances were partly inspired by cybernetics, a transdisciplinary development in the sciences that was also organised around the ontological ambiguity of the brain as the instrumental locus of subjectivity. Classic cybernetics was expressed in books such as *The Computer and the Brain* (<span>von Neumann</span>, 1958) or *The Brain of the Firm* (Beer, 1972), and analysed in works such as the aforementioned *The Cybernetic Brain* (Pickering, 2010) or *The Mechanization of the Mind* (Dupuy, 2000). Cybernetic theories gave a good basis for technological determinist arguments (“solutionism”): e.g. that social problems can be transformed *to* and eventually solved *as* technological problems. In other words, that revolution can be engineered (Söderberg, 2014). Most commentators, such as Tiqqun (2012) or Dammbeck (2003) draw dire conclusions from these notions, arguing that cybernetics grew into an overarching ideology justifying a more oppressive and exploitative society. Such analysis is both profoundly true and necessary to address political problems of our times. However, it takes for granted that there is a single unified essence of cybernetics, and all the originality of the cybernetic world view have been absorbed into the capitalist system.

On the other hand, Pickering single-handedly advanced a more positive outlook based on an alternative reading of British cybernetics, picturing it as an antidote to modernity’s blind paths. I suggest that the two readings – symmetric and asymmetric cybernetics (Pickering, 2013) – share an experience of subjectivity, which is first and foremost an encounter with objectivity: human intentionality with the material unknown. Their paths bifurcate in the moment of an ethical decision about how to handle the encounter. To rephrase Ross Ashby’s remark on Clausewitz: “Who will adapt to who?” (Pickering, 2010: 140). Engineering in general, and computer science in particular, serve as fertile grounds for experimenting with the ethics and epistemology of such an encounter, in light of its ontological implications. It makes sense that hackers, – as participants in an *alternative* engineering *subculture* – explored a different aspect of cybernetics than what has been absorbed into mainstream institutions.

The ambiguity of cybernetics and its close connection to computerised subcultures is aptly described by Christopher Kelty (2010) in an introduction to a special issue of Anthropological Quarterly on the topic:

> The “cybernetic-informatic consciousness” that he uses to link journalists and anthropologists together opens a door to understanding why computers and cultures are equally everywhere today – and maybe for some surprising reasons that have a lot to do with the mid-century successes of both cybernetics and anthropology. Cybernetics’ fortunes look a lot like culture’s – overused, diffuse, heavily critiqued, yet nonetheless compelling in their most rigorous forms. Cybernetics’ dissemination looks a lot like culture’s – taken up across nearly every discipline, attenuated by circulation, unpoliced by classic disciplinary modes of ownership and exclusion.

Indeed, there is consensus between scholars that cybernetics started as a scientific paradigm, but quickly disseminated into other spheres such as psychiatric practice (Pickering, 2010), the arts (MacGregor, 2002; Reichardt, 1968) and its own subsequent branches such as chaos theory. Perhaps more than other cultural movements, the European hacker tradition soaked up motifs of cybernetics in its fabric, with a special emphasis on *chaos theory*. The latter became the organising principle for an engineering subculture that – especially in Europe – grew up on the fringes.[3]

Since autonomist struggles ran out of steam in the 1970s (Cuninghame, 2005; Geronimo, 2012; Schultze and Gross, 1997; Wright, 2002), the advent of chaos theory was perhaps the only and last hope for revolutionary change. If a very small, but incredibly smart move can produce systemic change, than a hacker coupled with a computer can save the world. Another – less radical – interpretation invested its faith in the instability of systems where small changes can propel into phase changes pretty quickly. The latter interpretation put the apparent stability of “the system”[4] in perspective, and allowed for revolution almost by accident. What is essential, however, is that both interpretations empowered marginal social actors[5] with much more freedom than what contemporary political ideologies (activist or not) or current systems theory (scientific or not) allowed. In the era branded as the *Information Age* (Kline, 2015) ruled by Shannon’s statistical approach to communication, *noise* became the rallying cry of outsiders (Krapp, 2011 i-xx; Menkman, 2011) – and as a corollary, positive feedback[6] the analogue to the revolutionary process (Larsen, 2011). In a chaotic world, therefore, *adaptation* was the key for survival, resiliency and perseverance.

No other person represented such tendencies better than Wau Holland (Herwart Holland-Moritz). In 1980s Germany he was as much a public intellectual as a public engineer, as much an educator as an inventor. Underpinning his ideology about universal access to computers and networks, as well as the protection of private information and the free flow of public knowledge, were devices and practices as much as discourses (Kulla, 2003). He founded the Chaos Computer Club to advance these causes and legitimise hacker practices. In an incident that is now part of “German computer science folklore” (Wikipedia contributors, 2015a) members wired 134,000 DMs to themselves and presented the pile of money to the press after the German postal service (which held a monopoly on home banking) refused to fix the security issues they reported in its BTX system (Denker, 2014). They saw the broken implementation of encryption for online banking as a social problem, but authorities did not heed their advice. Therefore, they *demonstrated* the problem in the long tradition of the *public experiment* (Born and Barry, 2013): creating an ontological theatre which not only represented or described, but actually *performed* the vulnerability of informatic systems. The small action by these peripheral actors lead to the rehauling of the BTX as a national information infrastructure and helped to introduce competition to home banking. At the same time, it earned a good reputation for hackers for acting in the public interest. I argue later on that such formational experiences cemented hackers’ trust in practice and performance over theory and representation. Soon, chaos theory figured in the name of what is now the largest and most influential hacker organisation on the continent (Brooke, 2011):

> The Club was so named not because it set out to cause chaos but rather because one of the founders, Wau Holland, felt chaos theory offered the best explanation for how the world actually worked. Dutch hacker and entrepreneur Rop Gonggrijp says the club is about “adapting to a world which is (and always has been) much more chaotic and non-deterministic than is often believed”.

The Club was founded on December 12, 1981, at a table belonging to Kommune 1, an emblematic site of the autonomist movement, suggesting both continuity with, and departure from the ideas and practices of the extra-parliamentary left (Club, 1981, 2009; Wunschick, 2015). Chaos theory came to be officially embraced in the hacker scene as an explanation of *how the world actually worked*. In other words, an ontology, and one hinged on performance. Wau Holland explained that the goal was “causing Chaos as a means to display asymmetrical practices of Surveillance and control” (Kulla, 2003: 14).[7] The organisation of hackers was itself to function as an ontological theatre: a public display of a chaotic world. “Hence the most personal manifestation of Chaos was the computer club of the same name, whose speakers persisted with nearly missionary fervor that there is no security, that it is nothing but a nice yet deceiving illusion” (Kulla, 2003: 30).[8]

Following the establishment of regular hacker meetings such as the yearly Chaos Communication Congress (now in its 33rd edition), the proliferation of shared machine shops ushered in a subsequent period of hacking. These served as club houses for the hackers who could now organise publicly. One of the first was c-base in 1995, continuing the ***c***ybernetics, ***c***yberpunk, ***c***omputer associations. However, the mainstream success of hackerspaces started with Metalab in Vienna, which was initially proposed as KyBase (“Cybernetic Base”) in 2005.[9] This was not an accident because the hacker group behind the idea was called Wiener Kybernetischer Kreis: a word play on the name of cybernetics founder Norbert Wiener, and the interdisciplinary Vienna Circle (“Wiener Kreis”) that played a decisive role in the intellectual trajectory of the 20th century (Stadler, 2001; Wikipedia contributors, 2015b). However, hackers decided that references to cybernetics were too obscure to draw a more diverse audience, and called their base Metalab instead. Indeed, Metalab then provided the blueprint and inspiration for many subsequent hackerspaces (Bre and Astera, 2008: 7, 68, 87).

Hackerspace Brussels (HSBXL) materialised in 2008, while hackerspaces were exploding in numbers. Its identity also plays on Norbert Wiener, who is pictured in the logo wearing *flicker glasses* (Hackerspace Brussels Wiki contributors, 2010). Flicker glasses are essentially sunglasses fitted with LEDs on the inside, which simulate the brain by flashing in specific patterns. Pickering notes that they are descendants of British cybernetic artist and inventor Brion Gysin’s Dreamachine: a revolving tube dotted with holes that produced a similar effect thanks to internal illumination (419). It was built in collaboration with Ian Sommerville, a computer programmer and companion of Burroughs and other Beats. The invention was inspired by The Living Brain, (Walter, 1963), the book of a seminal British cybernetician. Walter was the first to describe the psychological effects of flicker (“The Central Effects of Rhythmic Sensory Stimulation”; 1949). He later commented on the commercial success of stroboscopes in discos to the effect that he should be paid a royalty (Pickering, 2010: 78–83). Much like other cybernetic motifs, flicker arrived to European hackers through American mediation. It was the San Francisco-based Mitch Altman who popularised remakes of the device in hacker circles (Cornfield Electronics, Inc., 2013). He soon acquired a standing in the hackerspaces scene comparable to Wau Holland’s role earlier, spending much of the year travelling between hacker clubs, teaching soldering and electronics while spreading a DIY[10] anti-military message. The emblem of his teachings came to be the Tripglass, which participants could assemble at soldering workshops.[11] One could go on recounting other instances of cybernetic figurations in European hacking (such as Maxigas, 2015: 272–3), but let three examples suffice for suggesting a pattern.

To summarise, in the 1950s and 1960s both hacking and cybernetics emerged from the socialisation and systematisation of Second World War techno-scientific advances, at a specific moment characterised by ample funds for base research (at least in the United States). Notwithstanding their origins in the academic-military-industrial complex, they were closely intertwined with the countercultural movements that flourished in their wake (Turner, 2006). As both tendencies show, the relationship between science and technology drew ever more close, yet it is fair to argue that cybernetics was articulated primarily as a scientific culture, while hacking as an engineering culture.

Throughout the 1970s and 1980s cybernetics – often through chaos theory – provided a much needed explanation of how the world actually worked to hackers who acquired an identity as a movement and a self-image as the underdogs of engineering. Semi-underground scenes formed, which often clashed with larger social structures like the authorities or corporations (Sterling, 1992). Hackers started to reflect on their socio-political roles and responsibilities as renegade engineers, especially in the European context, where links with social movements were stronger (Maxigas, 2012).

Since the 1990s, prominent personalities and organisations in the European hacker tradition were aware of some classic cybernetic tropes, artefacts and theories. Even if the translation of cybernetics into hacker culture has been very superficial, partial and fragmented, it remains that cybernetic motifs were woven into its fabric. This is not to suggest that the structural similarities between the ontology enacted by Pickering’s cyberneticians and the ontology performed through hackers’ practices can be explained by a shared genealogy. The use of cybernetic imagery in hacker culture is not internally coherent, even if its presence is consistent. For instance, where hackers champion chaos, their idol Norbert Wiener may champion order. Kline (2015: 96) shows that Wiener appeared to the average American as a humanist enemy of chaos:

> In his masterwork, America as a Civilization (1957), journalist and educator Max Lerner quoted Wiener’s idea that “communication is a dialogue between people united against the common enemy, whether we call it entropy or chaos.” It was one of the few popular references to Wiener’s extensive discussion of entropy in his books.

Instead of a history of ideas, figurations of cybernetics (especially chaos theory) in European hacking amount to a *reconfiguration* of cultural historical imaginaries “that hold particular relations of persons and things – with land, or with information – in place” through a simultaneous reflexive and generative movement, including leakages and entanglements (Suchman, 2012: 52, 58). Cybernetic motifs *worked* for hackers, generating theoretical insights and practical results that both guided their understanding of themselves in the world, and helped to orient their technological endeavours. As I proceed to present in the next sections, everyday enactments of a cybernetic ontology are more deeply ingrained in hacker culture than a reflection on the scientific content or motives of cybernetics.

<!-- Notes -->
Practices favouring practice
============================

Before introducing *engineering* practices, I would like to recount a scene that everyone can relate to. An unspecified francophone hackerspace got flooded in June 2015 because the landlord repeatedly refused to fix the roof of the old factory. Equipment was damaged and water covered a large part of the premises. A member proposed to drill a hole in the floor and sweep water down to the workshop of the landlord below the club. The idea was adopted on a whim, and since machine tools were stocked in the hackerspace, the hole was ready in a matter of minutes. The hackers did not bring it up with the landlord, but he fixed the roof the next week.

What I find revealing about the incident is that members were “thinking” directly in material agencies and how to mobilise them, sidestepping institutions and symbolic communication between humans. Just like in the case of the BTX, it was not enough to report vulnerabilities in the infrastructure: *hackers had to demonstrate them with a performance*. Instead of talking, then, the hackers had to do something to get their point across. Moreover, instead of mopping up the water, they accommodated its resistance by letting it continue its flow through the space. They entered a risky situation in the course of the exercise, which could have gone in different unexpected ways, and they were ready to accept the consequences. The most striking aspect for me, observing the scene, was how little discussion and hesitation went into it. I was clearly immersed in a culture that favours practice over representation, and performance over cognition, ready to go where material agency takes the engineer.

Exploratory programming
-----------------------

According to computer science professor Keunwoo Lee (2004), **exploratory programming** is about “programming by ’trying stuff out’ and seeing what happens”. It is a programming methodology taught in computer science and recommended for tackling problems that are not well understood. For the same reason, it is ideal for learning by doing. Since hackerspace members are not required to produce anything in particular, but often eager to learn, it is not surprising that exploratory programming is popular amongst them. Compared to their counterparts with monolithic institutional backgrounds, programmers in hackerspaces tend to meddle into a higher number of programming languages, paradigms and problems. While CTOs and computer science teachers often enforce a homogeneous technological repertoire in their institutions, experience with a particular technology or problem domain is not a criteria for hackerspace membership – only technical curiosity is. Just to follow the intricate jokes that Coleman (2012) pinpoints as the pinnacle of hacker culture, one has to know the basics of the dozen most popular programming languages. Of course, once members actually start to build things in their favourite languages, some of those things become part of the infrastructure for running the space, at which point – like it or not – more members will have to know at least how to repair them.

Conversely – like in any organisation – there *are* in fact favourite (if not so exclusive) languages in hackerspaces: Python and LISP. Python, which allows for a high level of reflection; and LISP, the ultimate “programmable programming language”. Reflection and programmability both support the exploratory programming paradigm, because they allow programmers more opportunity to understand and change programming language behaviour. Exploratory programming is most interesting when it is used to understand a particular property of the programming language itself, or even when it is loosely concentrated on a problem domain, rather than a particular real-world problem. The methodology and its technical repertoire is designed to iterate over possible solutions and hopefully find new ones through the process.

Therefore, exploratory programming is a methodology to engage with the temporal emergence of material agency in order to find a way to approach a problem that was not obvious before. Material agency in this context simply means that algorithms, languages and environments exhibit resistance in an analogous way to the physical reality that physicists – or mechanical engineers – face. Pickering (1995) already recognises the materiality of human language and abstract theories, so this is but a small extension to the theory of resistance and accommodation. The temporal emergence of material agency simply means that there is no way to know if something will work or not, that is until it has been tried out in practice. Even then, in case of failures it is impossible to know if there *is* a way to make it work. Practices that respect the temporal emergence of material agency are distinguished by the possible range of consequences that the resistance of the material may have on the overall endeavour.

Exploratory programming allows the programmer to engage with the unknown encountered during programming by changing the entire orientation of the activity, to the point where even the problem set out to be explored may shift. Similar conclusions have been reached by scholars of Human-Computer Interaction. Lindell (2014) is interested in the materiality of programming and craftsmanship in software development in the sense of Sennett (2009). His claim is that exploratory programming “mainly describes a conversation with the material”. I return to the idea of the conversation as the central metaphor for ontological ethics in the penultimate section.

One Autumn afternoon I sat around the table with several members in the hackerspace of Budapest.[12] One of the best programmers of the club happily announced that he is ready with paid company work, so now it is time to start another side project. After a few hours of intense coding, I asked him what will the new program solve? He answered that it was not possible to know yet. I was astonished, because he already wrote so much (Python) code. It was as if he walked out in the wilderness without a destination. He was building a general system to programmatically parse web pages, but it was not clear yet what are the real world tasks where it could outperform existing solutions. This way of approaching a problem was very different from most average programming jobs, where coders are paid to implement a pre-written specification, or work with clients on improving a product incrementally.

It was close to blue skies research where ideas are tried out and practical applications can wait. Nonetheless, even academic researchers have to write research proposals, acquire funding and produce an institutionalised timeline of deliverables, not to mention answering to superiors. In this case, there was no supervisor or institutional framework, only a club created by hackers themselves to support tinkering with materials. Conversely, the result would not be directly remunerated by anything other than the experience itself, and perhaps the respect of peers.

While in most cases exploratory programming may not be so efficient as a less spontaneous software development methodology, it allows programmers to perform the part of their job closest to engagement with materiality: coding. Negotiating the task, designing the software architecture, writing the documentation – and in most cases implementing a ready-made specification – are all part of the programmers’ job that exploratory programming puts less emphasis on. While these activities arguably present their own resistances, it is not the resistance of the program code itself. Hacker culture values engaging with the resistance of the program code itself over other tasks involved in programming. As the hacker saying goes, “two hours of planning can save you two days of coding – but then again, two days of coding can save you from two hours of planning” (personal communication, Ralf Bendrath, 2007-11-09).

<!-- Notes -->
Penetration testing
-------------------

**Penetration testing** is about probing a technological system in order to find faults in it. It can be done with malicious intent, but it can also be done under contract, in order to improve security by reporting problems. Penetration testing can be thought of as an antonym of the scientific experiment. While in a classic scientific experiment the point is to create an isolated environment where a repeatable operation is carried out in order to prove a hypothesis, the point of penetration testing is that it takes place outside of the laboratory, carried out on actual infrastructure through means that are difficult to foresee, in order to find problems in practice. For instance, banks are generally required to hire security companies to make sure that their infrastructure conforms to the relevant industry standards (such as ISO/IEC 27002:2007, 21188:2006, etc.). Many hackers run such companies. Others practice penetration testing in teams at *Capture the Flag* events, which typically last for a few sleepless days, and became a staple of hacker conventions. Online platforms set up for the pleasure and pain of playing penetration testing are called *wargames*.

Penetration testing can include anything from breaking into a computer network, through physical security like stealing paper documents, to social engineering where the attacker talks their way to sensitive information. However, these are related practices requiring a similar mindset. Here, the focus is on software security, because it is the most widespread area of expertise in hackerspaces.[13]

My claim is that in order to even begin working on penetration testing, one first has to accept that there is a gaping field to be explored between representation and performance. Most programmers and administrators *must* assume that the actual performance of a program is more or less accurately described in its specification, because it is but a building block of their systems. On the contrary, penetration testers could not even start their work without assuming that the program actually behaves differently under certain circumstances. It is *those* circumstances that the penetration tester is interested in, and most often they are to be found by trying out applications in a wide variety of ways, while looking for typical integration mistakes and known flaws in the individual components. However, the real prize of a penetration tester is a grave but unforeseen implementation mistake, one with interesting unintended consequences. Those latter can be developed into new ways to compromise the system: *vulnerabilities* [^CVE]. Previously unknown vulnerabilities are called *zero days*, because vendors, developers and administrators have had no opportunity to fix them yet. They play an important part in hackers’ imaginaries, reputation and economies.

Vulnerabilities are effectively the (most lucrative) products of penetration testers. Hackers construct vulnerabilities by engaging with the material resistance of an infrastructure, often through long time periods. Therefore, vulnerabilities are a good example of temporal emergence. A vulnerability report is often a mere description of a weakness, but eminent vulnerability reports also include *exploits*. An exploit is a short piece of code that demonstrates the vulnerability by triggering it in practice. Therefore, exploits can be used to compromise systems even by people who have only basic informatics knowledge. [^kiddies] Exploits are also recognised for their exchange value and consequently brought and sold on the black market, or acquired legally by vendors through bug bounty programs, or even reported on public mailing lists by independent researchers (similarly to academic findings in scientific journals). In the latter cases, exploits and vulnerabilities are meticulously credited, attesting to their status as products.

Exploits can be conceptualised as ontological theatres, which extort systems into strange performances. “No system is secure” is a mantra of hackers and each vulnerability is an additional proof of this point. Vulnerabilities are studied by hackers both for “fun and profit”. Their entertainment value comes from the fact that they achieve some unusual, often seemingly impossible task – like gaining administration rights to a system without knowledge of the appropriate credentials. The roots of the vulnerability lay in the unintended consequences of software written by developers, or the actions of the system administrators who run the vulnerable systems. Since the consequences are unintended, most vulnerabilities are discovered by examining the performance of the systems in practice, rather than the underlying theories, even though the vulnerability may prove the theory behind the system flawed. [^backdoors] Therefore, a vulnerability is often theoretically impossible, and by definition unknown before its discovery. The penetration tester have to be open to the unknown and do things that invite it to manifest itself. There are penetration testing methodologies taught at universities, but searching for vulnerabilities remains a craft that requires a calling, rather than a routine procedure that can be described in manuals.

An ontological theatre does not only take advantage of a particular ontological outlook in its design, but also showcases it through its performance. As a living proof that a system does not only work as advertised, but also in other “strange” ways, an exploit points to the distance between representation and performance. Such a performance is “strange” because it goes beyond – and very often against – the way given system is supposed to work. As such it also showcases and legitimises the epistemological advantages of working in close consideration of the cybernetic ontology.

<!-- Notes -->
Hardware hacking
----------------

Hardware hacking is arguably the *raison d’être* of hackerspaces (Kostakis et al., 2014, Dafermos (2014), Maxigas (2014)). On the one hand, the rise of hardware hacking accentuated a need for hackers to join forces in clubs commanding their own real estate, because sharing the necessary manufacturing resources and tacit knowledges solely online is difficult. On the other hand, once various strands of hackers came together in the same premises, working on tangible artefacts of *physical computing* (Igoe and O’Sullivan, 2004) provided an opportunity for common engagement between enthusiasts of software, hardware, mechanics and more.[14] Electronics classes – especially introduction to rapid prototyping tools such as the Arduino line of microcontroller boards – are usually amongst the first organised activities in newly founded hackerspaces. Similarly, “Learn to solder” and “Soldering is easy” is the signature workshop and fanzine of the aforementioned hackerspaces personality Mitch Altman, who likes to give it in budding hackerspaces around the world.

<!-- [0. Motivation] -->
Hardware hacking can be conceptualised as the appropriation of more widely used rapid prototyping practices. Prototyping in an industry is typically practiced with an eye on developing a final product, or sometimes used in an academia to learn something specific. Rapidity, when it is applied to prototyping, refers to the fact that desktop manufacturing technologies such as 3D printing and development tools such as programmable microcontrollers can be used to speed up design and implementation of hardware.

I argue that the appropriation of rapid prototyping practices in hackerspaces may be driven by a desire for engagement with material resistances and strange performances. At the same time, it is enacted under specific material constraints answering to the wider structural constraints on hackerspaces. Of course, both desires and constraints can be similar in certain institutional settings. However, institutions adopt rapid prototyping as a means to an end, whether learning by doing, research and development, or straightforward product development. Even if some workers are motivated by the encounter with the material resistances and strange performances during product development, most companies are constructed as an organisation geared towards making products. Such is the modern relationship to technology – reflected in the discourse of *innovation*: instrumental rationality frames most organised engagements with technology. As a counterpoint, it seems that in the organisational environment of hackerspaces, encountering material resistances and strange performances is not a means to an end but an end in itself.

<!-- [1. Material constraints: flotsam] -->
Hardware hacking is highly dependent on the components and manufacturing equipment that developers can get their hands on. Ordering new components or acquiring funding is cumbersome and boring. Instead, hackerspaces maintain a junkyard of sorts for scavenging components. Any project or product – assembled or not – can fall prey to rapid prototyping in a hackerspace. Therefore, both purpose-made stickers (“Do Not Hack”) and ad-hoc notes (“Don’t Touch”) are used to distinguish *loot* from *work in progress* projects and *infrastructures* that are essential for operating the space. Members have lockers or boxes to keep their stuff away from prying hands.[15]

Hackerspaces are filled with the technological refuse of latter generations, to the point where several of them collect typewriters (used by typewriting clubs at Noisebridge, San Francisco or at Technologia Incognita, Amsterdam that meet regularly at the premises) and operate museums of working computers (for instance at Arnhem, The Netherlands or in Catania, Sicily). In turn, obsolete machine tools from factories and legacy laboratory equipment are sometimes dropped at hackerspaces. Technical solutions, design insights and salvaged components from these machines may become building blocks of prototypes. Constraints such as using readily available components and manufacturing tools are another form of material agency that plays its part in hardware hacking and emerges both historically and stochastically. Like the ontological theatres of the classic cyberneticians, a prototype made in a hackerspace often showcases an idea or an enigma, an intervention whose actual engineering could be deceptively simple or primitive – or its practical value questionable.

Returning to Coleman’s point that sophisticated in-jokes are the heart and soul of hacker culture, it can be argued that prototypes are often not more than elaborate practical jokes, a running commentary on the absurdity of rational instrumentalisation in modern technologies. A case in point is the common trick implemented in hackerspaces, where step-motors (of a 3D printer, laser cutter or even a stack of old CD-ROM drives) are used to generate evocative of popular classical music, such as the Empire theme from Star Wars. Rather than accomplishing a practical task, such contraptions function as ontological theatres showcasing strange performances of otherwise familiar machines.

When Latour (2008) writes about the virtues of design thinking as an amodern form of thought, he emphasises that design always starts with something which is already there. Therefore, design is always redesign. For Latour, this is in opposition to the Promethean hubris of modernity where the inventor is supposed to create ex nihilo. Latour praises the careful humility of design which never starts from scratch, but shapes things attentive to the circumstances. However, it is curious that it never occured to the author of *We Have Never Been Modern* that Prometheus actually stole the fire rather than invented it. The fire was already there, what happened is that it was made public. Nonetheless, Latour’s description sits well with rapid prototyping, which starts from the material available at hand, strives to create a functioning thing as soon as possible, and tinker on from there, rejecting “’destroy it all and build something completely different’ modernism” (Flynn, 2014).

<!-- [2. Tinkering] -->
What is carried on in the translation of rapid prototyping into hardware hacking is the conviction that practice, not theory – materials, not blueprints – should guide development. The ontological commitment necessary for pursuing development in this way is to a world that is not infinitely knowable through what Pickering calls “positive knowledge” (a staple of modernity, see 2010, 401). In other words, there is no way to know how a prototype will turn out. Therefore, prototypes are built not only rapidly but in quick succession, so that every iteration can build on the practical experience gained. In the connected world of hackerspaces, this often means reproducing something that was done elsewhere, sometimes with personal help from the previous designer. Due to the haphazard source materials and other local factors, exact copies are downright impossible. Moreover, it is widely acknowledged that as long as the experience is new to a participant, rebuilding something old can be as rewarding as building something new.

<!-- [3. Uncertain futures] -->
Education, research and production in hackerspaces are mere corollaries to encounters with material agency that produce unpredictable effects. The irrelevance of the very categories that define modern institutions is demonstrated in how seamlessly they can blend into each other in the quotidian life of the hackerspace. In particular, prototypes made in hackerspaces often evade these modern categories of instrumentalisation. It may not be clear whether they are prototypes of personal projects, learning exercises, artworks, commercial products or activist interventions. Indeed, the very hackers working on the project are often altogether uninterested in such questions. At some point the project may be abandoned, nailed to the wall of the hackerspace as an example of how to (or how *not* to) connect two specific electronic components – or it could become an activist intervention in a political debate, but just as well provide the basis for a lucrative startup. These destinies matter little when the point of the process is to encounter the unknown on a common ground.

<!-- Notes -->
Odd institutions hosting strange performances
=============================================

The “lack of material and social discipline” is the double thread that ties together the trio of ontological theatres emblematic of UK cybernetics: Grey Walter’s tortoises, Ross Ashby’s homeostats and Gordon Pask’s Musicolour (Pickering, 2010: 324).

Materially, they were constructed from the junk left over after the Second World War: surplus bomb relays from the RAF and obsolete telephone relays from the Post Office. “Elizabeth Pask (n.d.) recalled that Gordon and Harry Moore built Musicolour from ’old relays and uniselectors junked from post office telephone exchanges’ – the same components that Walter and Ashby used in their model brains” (Ibid.).[16] In fact, cybernetics itself was largely a product of synthesising the theoretical and technical legacy of the war effort coming “out of the detritus of war and a technological society” (Ibid.). But what is more crucial for the present argument is that the design and implementation of these artefacts was shaped by the technological debris of the time as a material force in its own right.

I have demonstrated at lengths that hardware hacking relies on a similarly haphazard ensemble of refuse – a refuse that is only structured by the fact that these components and machines spilled over to the hackerspace from modern institutions such as companies and laboratories where they were deemed obsolete or superfluous. In this sense it is not only the practices of hackers that fall outside modern categories but also the materials on which they act, let it be archaic programming languages such as LISP, or old machinery such as typewriters. It is no wonder that the results can be sometimes interpreted as a subversive commentary on the ideals of modern engineering.

Socially, UK cyberneticians pursued cybernetics as a side project barely tolerated by their respective institutions and hardly fitting into their respective disciplines. “I am struck, first, by the profound amateurism of British cybernetics. Key contributions often had an almost hobbyist character: Walter built his first tortoises at home in his spare time; so did Ashby his homeostat (at least, in the apocryphal version of the story); likewise Beer and Pask’s experimentation […]. Cybernetics welled up outside the usual channels, and it found little support within those channels” – writes Pickering (2010: 10). [^kitchen] Even if the results of British cybernetics have been distilled into (pseudo-)scientific books and articles, how the substance of the work was carried out was nothing short of tinkering with engineering in a largely peripheral setting.

Hackerspaces are likewise marginal engineering institutions, with the crucial difference that they were explicitly constructed to inhabit marginality as a counter-cultural position. For some of them, social marginality was a desirable position – for others it became a necessity. Either way, Coleman and Golub (2008) notes that repression as an outside pressure was instrumental for the organisation of the hacker scene, forging a compact set of ideas and practices that hackers held their own. Realising that their exploits and out of the box engineering culture goes beyond the confines of modern institutions, they banded together to pursue an alternative trajectory. Consequently, hacking is today a popular folk tradition that developed a relatively wide social basis, while cybernetics disseminated because it failed to reproduce its social basis.

From cybernetic ontologies to hacker ethics
===========================================

Ethics mediates between ontology and its performance in practice. Therefore, eliciting the ethical consequences of the view of the world distilled in the cybernetic ontology can further illuminate the practices described in the previous section, while preparing the ground for the political conclusions in the next section. Departing from Pickering (2010), I theorise the ethical consequences of the cybernetic ontology by way of the ontological ethics of Emmanuel Lévinas (1969).

The starting point of Lévinas’ ontological ethics is a Hegelian understanding of the Other as an existential threat to the phenomenological subject. The threat comes from the ambiguity of the Other between being another agent like me, but also fundamentally different. The proposed eminent ethical relationship with the Other is modelled on the conversation. In short, the conversation allows for keeping a distance and therefore recognising difference, while at the same time exposing oneself, and therefore be effected by the relationship. The conversation does not seek to destroy or assimilate the Other, but to learn and adapt to it. There are obvious parallels here with the Conversation Theory developed by the classic cybernetician Gordon Pask (1976). Moreover, neither authors conceptualised the conversation as necessarily verbal, leaving theories open for performative interpretations (such as Lindell, 2014). Lévinas uses further timely metaphors such as hosting the other in my home, but also falling hostage to the Other in a foreign land.

My suggestion is that this formulation of ontological ethics is descriptive of hackers’ relationship to material agency found in their interactions with machines, just like Pask’s experience with the Musicolor. In line with the unstable ontological divide between subjects and objects expressed in cyberpunk works, the Other takes an objective form in these experiences. While certainly a departure from Lévinas original thought, I hope that the recognition of the Other as the material resistance performed by objects explains many aspects of symmetric cybernetics as well as hacker culture.

Pickering recounts how Ashby’s prolonged struggle with prototyping DAMS made him abandon “the modern engineering paradigm of knowledge-based design in favor of evolutionary tinkering” (2010: 128) that “necessarily entailed a degree of *respect* for the other” (2010: 32). His desperation marked the ethical moment in cybernetics, and resonates well with hackers’ difficulties in exploratory programming, penetration testing or hardware hacking (described in Kleif and Faulkner, 2003). I argued that hackers such as penetration testers *construct* bugs through enacting an anti-modern ontology - yet vulnerabilities are always both unexpected and unsettling even to them. Technical expertise allows hackers to recognise the face of specific technical problems as strikingly familiar yet unsettlingly different: hence the fascination with security.

Echoing Lévinas’ claims about the construction of subjectivity in relation to the Other, I would explore the notion that hacker subjectivity is primarily ethical and constituted through subjection to the resistance of materials encountered in practice. On closer examination, each of the practices above share a few characteristics that point to such a realisation. All have to do with the recognition of material agency in the form of bugs, or glitches in computer science.

The resistance of the material manifests itself as a bug or glitch in a complex technological system. First, the creation of situations in which bugs can occur and unfold. Since bugs are the products of penetration testing, it is no wonder that security experts have mastered the art of summoning errors through unexpected inputs into the system. Second, accommodation but not recuperation of bugs into the development process. Exploratory programming is about meeting the full force of the problem in the very spontaneity of practice rather than solving it first theoretically. In hardware hacking each iteration of a prototype has serious design flaws – since this is exactly what distinguishes it from a finished product.[17] Third, bugs resulting in unforeseen, and thus potentially unexpected and potentially dangerous results. I would like to emphasise once again the exploratory nature of drilling a whole on your floor (which is the ceiling of your landlord). It is hard to argue that it is a safe approach to conflict resolution. The strength of the gesture is not in finding a safe solution but on the contrary: opening up the possibility of an unexpected, if dangerous solution to work out or not.

As ontological notions of ethics should, such formulation of hackers’ ethical experience logically precede Levy’s (1984) list of concrete commandments. In light of ontological exegesis, the spirit of the commandments is to remove particular barriers – remnants of modernity – that could interfere with the existential encounter between subject and object, user and computer, and give free reign to performativity. The first and last commandments – “All information should be free” and “Computers can change your life for the better” are explicitly written in the performative idiom that recognises material agency. The intermediate ones target modern social institutions such as bureaucracies, prejudices (sexism, racism, etc.) and instrumental rationality (in opposition to art and beauty).

The ontological interpretation puts connections with classic liberalism tackled by Coleman and Golub (2008) in a new perspective: anti-racism, for instance, is not a commitment of solidarity with the downtrodden, but a precondition for the materiality of the code to speak for itself. As Coleman puts it, “Hacking, even if tethered to liberal ideologies, spills beyond and exceeds liberal tenets or liberal notions of personhood” (2012: 4). Liberalism might be merely a precondition for including non-humans in the cosmopolitics of hackers.

The moral of the story is that bugs function analogously to Lévinas’ Other in the diagram of the hackers’ engineering culture. Once this assertion is secured, the consistency of the exploratory practices and ethical commitments above is apparent, as well as the common ground of politics that grows out of them. The unknown is sought out for the experience of the encounter and material agency is accommodated, but not recuperated into the engineering enterprises of hackers. Furthermore, as I argue in the previous section, the organisational infrastructures of the scene are built to accommodate such an ethical relation with the unknown – unlike modern institutions.

Conclusion
==========

Anti-modern techno-science society
----------------------------------

Finally, we are in a position to ask the crucial question: how does hackers’ enactment of a particular ontology – through practices, organisations and forms of life that take into account that ontology – challenge modernity? Latour (1993) criticised modernity as a series of purification processes that seek to counter a parallel process of hybridisation: an ontological horror that the cyberpunk imaginary captures suggestively. I suggest that hacking as an alternative engineering culture features some practices that are articulated against modern institutional best practices: against specifications that can be translated into working software, information infrastructures that can be secured, prototypes that can be turned into perfect products. As Latour advocated in his works since, culture and institutions have to be reinvented and rebuilt so that they are not conditioned by such disastrous modern myths. Hacker scenes include some organisational forms such as the hackerspaces that provide the social basis for the sort of hybridisation that modern institutions are meant to prevent – for instance between education, research and production. Finally, I theorise that hackers’ diverse and sometimes contradictory ethical commitments and political interventions can be, perhaps, understood on the basis of an ontological ethics. Lévinas’ work on the encounter with the Other is a good entry point, even if hacker subjectivity is constructed in relation to the non-human, material agency found in technical problems.

The most significant contribution of hackers to the project of surpassing modernity may well be establishing popular genres of engineering and setting up organisations that are constructed in a way that points beyond the modern view of the world. A kaleidoscopic overview such as this article can identify patterns that are worth exploring but does little in way of arguing concrete cases. Further studies are needed to understand the historical trajectory, ontological sensibilities, and social content of these practices and how they come together in innovative organisational forms such as the hackerspaces.

In the meantime, hacking addresses new audiences (such as women and children) and incorporates new techniques (such as synthetic biology) – but it has also been absorbed into modern institutions such as political parties, university campuses and international corporations. Delfanti (2013) notes that these tendencies testify to the versatility and complexity of the hacking phenomena, but also contribute to its diffusion. Ironically, if cyberneticians failed to reproduce their social basis, the success of hacker culture could have a similar effect on its ontological dimensions, as much as it is recuperated by contemporary pop culture and late modern capital accumulation (Söderberg and Delfanti, 2015).

Cybernetics vs. hackerdom
-------------------------

Notwithstanding the connections established so far, hacker practices differ from those explored by Pickering in three major ways. First, **hacking is anti-modern** since it is deliberately articulated in opposition to modern practices. Hackers – even powerful ones – have always positioned themselves on the periphery of modern society and regarded their movement as an anomaly – even if an inevitable one. The practices above have each been developed in diametrical opposition to industry best practices of mainstream engineering. A single example would be penetration testing which is part of the *offensive security* tradition, which challenged assumptions that building a secure system according to specifications is sufficient for resilience, advocating that all security experts have to be familiar with the mindsets, skill sets and tool sets of attackers.[18]

Second, ***hackers can reproduce their social basis*** through an expanding network of hackerspaces, periodic meetings and online communities. While classic cybernetics revolved around the cyberneticians themselves, hacking is organised around practices which can be appropriated by anybody. Hacking, like popular culture, is contained in and communicated through genres. Classic cybernetics did practice and propose organisational innovations from the dinner societies of the UK cyberneticians through the Kingsley Hall and Archway communities to the Fun Palace. However, scenes of hackers have been arguably more innovative, more concentrated and more successful in organisational innovations. From underground phreaking groups that convened on telephone networks, through security conferences in festive settings, to hackerspaces accessible to the general public, hackers found different ways to reproduce their culture and pass it on to the subsequent generations. Indeed, one may say that hackers are more focused on collectively perpetuating their folk culture than classic cyberneticians were.

Third, ***hacker culture is organised around engineering***, while the cybernetic ontology was originally articulated as a scientific culture. Of course, since both point beyond modern categories, both disseminated beyond their surface of emergence, even if retaining a heartland in science or engineering, respectively. In fact, it could be argued that the decline of classic cybernetics and the rise of hacker culture are both embedded in a larger process, where engineering itself is becoming hegemonic not just in its relation to science but many more areas of social life. The popularisation and recuperation of hacking are both happening through the appropriation of engineering practices and metaphors.

Summary
-------

Throughout the article I pick up practices strategically where the cybernetic ontology manifests in hacker practices as ontological theatres (showcasing another way of approaching material agency). Notwithstanding such selective bias, I believe that a similar outlook is present, albeit in a much more diluted form, in many areas of hacker culture. The deep hacker studies research program is grounded in the hypothesis that the sociological implications of enacting such an ontology – perhaps mediated by an ethical regime – can help to understand specific areas where hackers made contributions. For instance, the disruptive effects of practices as disparate as hacktivism, online piracy, digital fabrication or free software may find a common vector of explanation in ontological analysis. On a final note, I argued that hackers’ efforts to research and organise in close consideration of an anti-modern view of the world – the socialisation of cybernetics, if you like – spawned a vibrant popular culture with wide implications for technology, science and society.[19]

References
==========

Barbrook, R. and A. Cameron (1996) ‘The Californian Ideology’, *Science as Culture* 26: 44–72.

Beer, S. (1972) *The Brain of the Firm* (First.). London: Allen Lane, The Penguin Press.

Born, G. and A. Barry (2013) ‘Art-Science: From Public Understanding to Public Experiment’, pp. 247–72 in Barry, A. and Born, G. (eds), *Interdisciplinarity: Reconfigurations of the Social and Natural Sciences*, Culture, Economy and the Social (First edition.). Routledge. URL <http://libgen.io/book/index.php?md5=7617b674bdf31db99c5e264348cfb073>

Bre and Astera (eds) (2008) ‘Hackerspaces: The Beginning’.

Brooke, H. (2011, August) ‘Inside the Secret World of Hackers’.

Bundy, A. (2009) ‘Prospects of Artificial Intelligence’, in Wand, I. and Milner, R. (eds), *Computing Tomorrow: Future Research Directions in Computer Science* (Reissue edition.). Cambridge: Cambridge University Press.

Cavallaro, D. (2000) *Cyberpunk & Cyberculture: Science Fiction and the Work of William Gibson* (First edition.). London; New Brunswick, NJ: The Athlone Press.

Club, C.C. (1981, December) ‘Founding Document’.

Club, C.C. (2009, November) ‘Chaos Computer Club’.

Coleman, G. (2012) *Coding Freedom: The Ethics and Aesthetics of Hacking*. Princeton, NJ: Princeton University Press.

Coleman, G. and A. Golub (2008) ‘Hacker Practice: Moral Genres and the Cultural Articulation of Liberalism’, *Anthropological Theory* 8(3): 255–77.

Cornfield Electronics, Inc. (2013) ‘Tripglasses Product Page’.

Cuninghame, P. (2005) ‘Autonomia in the 1970s: The Refusal of Work, the Party and Power’, *Cultural Studies Review* 11(2): 77–94.

Curtis, A. (2011, May) ‘All Watched over by Machines of Loving Grace’.

Dafermos, G. (2014, June) ‘Distributed Manufacturing: Commons-Oriented Productive Capacities’.

Dammbeck, L. (2003) ‘Das Netz’.

Delfanti, A. (2013) *Biohackers: The Politics of Open Science*. London: Pluto Press.

Denker, K. (2014) ‘Heroes yet Criminals of the German Computer Revolution’, pp. 167–88 in Alberts, G. and Oldenziel, R. (eds), *Hacking Europe: From Computer Cultures to Demoscenes*, History of Computing (First edition.). London; Heidelberg; New York; Dordrecht: Springer-Verlag.

Dupuy, J.-P. (2000) *The Mechanization of the Mind: On the Origins of Cognitive Science*. Princeton, NJ; Oxford: Princeton University Press.

Flynn, A. (2014, September) ‘Solarpunk: Notes Toward a Manifesto’.

Geronimo (2012) *Fire and Flames: A History of the German Autonomist Movement*. Oakland, CA: PM Press.

Grant, I.H. (1998) ‘Cyberpunk’, pp. 263–4 in Mulvey-Roberts, M. (ed.), *The Handbook to Gothic Literature*. New York: NYU Press.

Hackerspace Brussels Wiki contributors (2010, Auguest) ‘Who’s That Dude?: NorbertWiener’.

Igoe, T. and D. O’Sullivan (2004) *Physical Computing: Sensing and Controlling the Physical World with Computers*. London: Premier Press.

Juul, M. (2010, April) ‘Don’t Hack My Tools!’

Kelty, C. (2010) ‘Culture in, Culture Out’, *Anthropological Quarterly* 83(1): 7–16.

Kleif, T. and W. Faulkner (2003) ‘“I’m No Athlete [but] I Can Make This Thing Dance!”: Men’s Pleasures in Technology’, *Science, Technology and Human Values* 28(2): 296–325.

Kline, R.R. (2015) *The Cybernetics Moment: Or Why We Call Our Age the Information Age*. Baltimore, MA: Johns Hopkins University Press. URL <http://gen.lib.rus.ec/book/index.php?md5=a47edd2b6d741ffd8c3fcb303d9932df>

Kostakis, V. et al. (2014) ‘Production and Governance in Hackerspaces: A Manifestation of Commons-Based Peer Production in the Physical Realm?’, *International Journal of Cultural Studies*.

Krapp, P. (2011) *Noise Channels: Glitch and Error in Digital Culture*, Electronic Mediations. Minneapolis, MN; London: University of Minnesota Press.

Kulla, D. (2003) *Der Phrasenprüfer: Szenen Aus Dem Leben von Wau Holland, Mitbegründer Des Chaos-Computer-Clubs [the Voltage Tester - Scenes from the Life of Wau Holland, Co-Founder of the Chaos Computer Clubs]*. Werner Pieper & The Grüne Kraft.

Larsen, L.B. (2011) ‘Anti-Disciplinary Feedback and the Will to Effect’, *Mute Magazine: We Gladly Feast on Those Who Would Subdue Us* 3(1).

Latour, B. (1993) *We Have Never Been Modern*. Cambridge, MA: Harvard University Press.

Latour, B. (2008, September) ‘A Cautious Prometheus? A Few Steps Toward a Philosophy of Design (with Special Attention to Peter Sloterdijk)’.

Leary, T. (1994) *Chaos and Cyber Culture*. Berkeley, CA: Ronin Publishing.

Lee, K. (2004, February) ‘Exploratory Programming Using Squeak and Morphic’.

Levy, S. (1984) *Hackers: Heroes of the Computer Revolution*. Anchor Press, Doubleday.

Lévinas, E. (1969) *Totality and Infinity: An Essay on Exteriority*. Pittsburgh, PA: Duquesne University Press.

Lindell, R. (2014) ‘Crafting Interaction: The Epistemology of Modern Programming’, *Personal and Ubiquitous Computing* 18(3).

MacGregor, B. (2002) ‘Cybernetic Serendipity Revisited’, pp. 11–3 in *C&C ’02 Proceedings of the 4th Conference on Creativity & Cognition*.

Markoff, J. (2005) *What the Dormouse Said: How the Sixties Counter Culture Shaped the Personal Computer Industry*. London: Penguin. URL <http://libgen.io/book/index.php?md5=631E8A3A67AB0EA19ECD3DB0E689ADA1>

Maxigas (2012) ‘Hacklabs and Hackerspaces — Tracing Two Genealogies’, *Journal of Peer Production* 2.

Maxigas (2014, June) ‘Hackerspaces: The Infrastructure of Open Hardware Production’.

Maxigas (2015, September) *Peer production of open hardware: Unfinished artefacts and architectures in the hackerspaces* (PhD thesis).

Menkman, R. (2011) *The Glitch Moment(um)*, Network Notebooks. Amsterdam: Institute of Network Cultures.

Pask, G. (1976) *Conversation Theory: Applications in Education and Epistemology*. New York: Elsevier.

Pickering, A. (1995) *The Mangle of Practice: Time, Agency, and Science*. Chicago, IL: University of Chicago Press. URL <http://libgen.io/book/index.php?md5=44ad4df824c04f1e8160cc16f61d2bec>

Pickering, A. (2010) *The Cybernetic Brain: Sketches of Another Future*. Chicago; London: University of Chicago Press.

Pickering, A. (2013, February) ‘Cybernetics and the Politics of the Dark Universe’.

Rapatzikou, T.G. (2004) *Gothic Motifs in the Fiction of William Gibson*, Postmodern Studies. Amsterdam; New York, NY: Rodopi.

Reichardt, J. (ed.) (1968) *Cybernetic Serendipity*. London: W. & J. Mackay. URL <http://cyberneticserendipity.com/cybernetic_serendipity.pdf>

Ross, A. (1990) ‘Hacking Away at the Counterculture’, *Postmodern Culture* 1(1).

Schultze, T. and A. Gross (1997) *Die Autonomen: Ursprünge, Entwicklung Und Profil Der Autonomen Bewegung Broschiert [the Autonomists: Origins, Development and Profile of the Autonomous Movement]*. Hamburg: Konkret Literatur Verlag.

Sennett, R. (2009) *The Craftsman*. New Haven; London: Yale University Press. URL <http://libgen.io/book/index.php?md5=DB85DF3B46F2E519A111FD5EB961084E>

Söderberg, J. (2014) ‘Reproducing Wealth Without Money, One 3D Printer at a Time: The Cunning of Instrumental Reason’, *Journal of Peer Production*(4).

Söderberg, J. and A. Delfanti (2015) ‘Hacking Hacked! The Life Cycles of Digital Innovation’, *Science, Technology and Human Values*: 1–6.

Srnicek, N. and A. Williams (2015) *Inventing the Future: Postcapitalism and a World Without Work* (First edition.). London; New York, NY: Verso.

Stadler, F. (2001) *The Vienna Circle: Studies in the Origins, Development, and Influence of Logical Empiricism*. Vienna; New York, NY: Springer.

Sterling, B. (1992) *The Hacker Crackdown: Law and Disorder on the Electronic Frontier*. New York: Bantam.

Suchman, L. (2012) ‘Configuration’, pp. 48–60 in Lury, C. and Wakeford, N. (eds), *Inventive Methods: The Happening of the Social*, Culture, Economy and the Social (First.). London; New York: Routledge. URL <http://libgen.io/book/index.php?md5=712B065634D6563D3D70051FB275602A>

Tiqqun (2012) *The Cybernetic Hypothesis*. The Anarchist Library. URL <http://theanarchistlibrary.org/library/tiqqun-the-cybernetic-hypothesis>

Turner, F. (2006) *From Counterculture to Cyberculture: Stewart Brand, the Whole Earth Network, and the Rise of Digital Utopianism*. Chicago, IL: University of Chicago Press. URL <http://libgen.io/book/index.php?md5=6916B53A2F276602174090943602E3F2>

<span>von Neumann</span>, J. (1958) *The Computer and the Brain* (Third edition.). New Haven, CT: Yale University Press.

Wallerstein, I. (2004) *World-Systems Analysis: An Introduction*. Durham; London: Duke University Press.

Walter, V.J. and W.G. Walter (1949) ‘The Central Effects of Rhythmic Sensory Stimulation’, *Electroencephalography and Clinical Neurophysiology* 1(57-86): 84.

Walter, W.G. (1963) *The Living Brain*. London: W. W. Norton & Company.

Whatley, J. (2014) ‘Gothic Self-Fashioning in Gibson’s Novels: Nature, Culture, Identity, Improvisation, and Cyberspace’, pp. 418–33 in Crow, C.L. (ed.), *A Companion to American Gothic*, Blackwell Companions to Literature and Culture (First edition.). Chichester: Wiley Blackwell.

Wikipedia contributors (2015a, October) ‘Bildschirmtext’.

Wikipedia contributors (2015b, September) ‘Metalab’.

Wright, S. (2002) *Storming Heaven: Class Composition and Struggle in Italian Autonomist Marxism*. London: Pluto Press.

Wunschick, F. (2015) ‘12 September 1981: Gründung Des Chaos Computer Club’.

Xinchejian hackerspace wiki contributors (2013, May) ‘Weekly Staff Meetings, 2013-05-21, Code of Conduct Draft’.

[1] For an ethnological account see Maxigas (2015)

[2] These ideas are not far from the arguments put forward by proponents of Left Accelerationism today (Srnicek and Williams, 2015).

[3] Incidentally, European cybernetics likewise developed in relative social marginality compared to its US counterpart (Pickering, 2010: 388).

[4] Whether economic, political, technical or even world system.

[5] Whether single individuals, small groups or subcultures.

[6] The self-amplification of noise.

[7] “Chaos stiften als Mittel als Mittel der Sichtbarmachung von asymmetrischen Praktiken der Überwachung und Kontrolle.”

[8] “Der erste Hackangriff rief den Schutzpatron der Sicherheit auf den Plan, die Ordnung. Chaos as a counterpole to the patronsaint of security, order/system.”

[9] Metalab was formally founded the next year (2006).

[10] Do It Yourself.

[11] Later the Tripglass was replaced by the TV-B-Gone universal remote control that can turn off any television. Mitch’s latest product is the Neurodreamer, a return to Gysin’s Dreamachine.

[12] The Hungarian Autonomous Center for Knowledge, alias H.A.C.K., located in Hungary.

[13] Hackerspaces often host lock picking sport clubs, and sometimes social engineering workshops too.

[14] Building hardware always already includes software engineering (for interfaces and especially the firmware) and mechanics (for the tangible components, especially robotics actuators).

[15] From the Code of Conduct draft of the Xinchejian Hackerspace in Shanghai: “DO NOT HACK means DO NOT HACK If you’re leaving something and you would rather it was not hacked, please label it with a DO NOT HACK notice. If you see something has a DO NOT HACK notice on, don’t hack it” (Xinchejian hackerspace wiki contributors, 2013). For other examples, see Juul (2010).

[16] “The only other reference I have found to Ashby’s source of parts for the homeostat is to the detritus of World War II: ’It has four ex RAF bomb control switch gear kits as its base, with four cubical aluminium boxes’ (3 March 1948, p. 2341).” (Pickering, 2010: 426)

[17] Indeed, debugging the prototype to get an actual product is most often more difficult and definitely more tiresome than developing an almost perfect prototype.

[18] Another evaluation of exploratory programming by scientists is from Bundy (2009) 37: “This exploratory programming methodology has been the target of much criticism of AI, especially from the theoretical computer science community. There are elements of both justice and unfairness in this criticism. Such an *ad hoc* methodology is no way to develop a robust program. It is the antithesis of the structured programming and formal methods advocated by software engineers.”

[19] With the support of a postdoctoral grant from the Universitat Oberta de Catalunya (UOC) and the sponsorship of the Central European University Foundation, Budapest (CEUBPF) for a fellowship at the Center for Media, Data and Society in the School of Public Policy.
