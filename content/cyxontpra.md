% Anti-Modern Techno-Science: Cybernetics, Ontology, Practice in the European Hacker Tradition
% Maxigas <maxigas@anargeek.net>
% Final draft (2016-10-01)

# Introduction

## The case for deep hacker studies

Hacker artefacts, knowledges, practices and scenes constitute an alternative engineering culture that can be characterised as anti-modern techno-science.  Constructed in the wake of the 1960s cultural shock [@Wallerstein2004a 16], hackers’ attitude to technology is reminiscent of the cybernetic ontology identified by @Pickering2010a and articulated in the sciences by cyberneticians.  It privileges practice over representation, performance over cognition, and adaptive encounters with the unknown over the domination of Nature.  In short, it is informed and forged by an experience in the ontology of becoming.

<!-- FIXME: Change the Wallerstein reference to the antisystemic movements book! -->

<!-- FIXME: human intentionality in an interactive relation with material agency? -->

While it has been demonstrated that even engineers and scientists working in the heart of modern institutions grapple with the mangle of practice in their daily routines [@Pickering1995a], it has also been pointed out that neither official accounts of engineering or scientific work, nor the institutions that frame them are necessarily constructed according to such realisations.  Simply put, the role of material agency in techno-scientific research is not taken into account adequately by modern institutional frameworks.  @Pickering2010a brought a historiography of scientists (the cyberneticians) who attempted to reformulate scientific tools, theories, practices and institutions to match their experiences in the ontology of becoming.  Starting from the figurations of cybernetics in European experiences of hacking, I argue here that an anti-modern techno-science can be shown to be at work in our contemporary historical horizon.  Some hacker practices do more than dealing with the contingencies of material resistance commonly encountered in research: these practices are designed to invite such encounters and encourage resistance to shape processes and results.  Furthermore, organisational forms of hackers encourage taking seriously such encounters rather than accomodating them to institutional expectations.  Once again, rather than claiming that hackers work with an ontologically different technology than mainstream engineers, what I seek to demonstrate is that *ontology matters* as part of culture.

Pickering shows that the classic cyberneticians’ non-modern approach was so transversal that it did not fit into the grid of modern institutions, and therefore they failed to reproduce their social basis.  What I intend to point out is that hackers’ practices are articulated in opposition to best practices in the academic-military-industrial complex to the point where they set up their own organisational infrastructures to sustain their scenes and reproduce their social basis.  In a more nuanced analysis below, I seek to capture the difference between how hackers and how cyberneticians enact a cybernetic ontology in the contrast between *non-modern* and *anti-modern* techno-science.

As Pickering when researching English cyberneticians, I am more interested in how to live and how to engineer in a different way, than to capture the essence or the statistical veracity of hackerdom.  The wealth of the empirical material is drawn from the European hacker tradition, but I do not claim that it captures the mainstream of hacking there or elsewhere.  I would rather like to chart an undercurrent of motifs that is theoretically revealing.  Everything that is laid down here is taken from my decade long anthropological and historical research into hackerspaces, but this time the ambition is not ethnological documentation ^[For an ethnological account see @Maxigas2015a].    Studying hackers offers lessons on how artefacts, knowledges, practices and even organisations can be different when the mangle of practice is taken into account in a more consistent and coherent manner.

Asking such questions is essential in a historical moment when late modernity seem to have exhausted its potential, so that we have to look at other ways of dealing with the world in order to find adequate responses to social, environmental, economical, political and institutional crises.  While hackers’ encounters with the unknown are certainly not enough to address these issues, they may possibly offer lessons about alternative pathsways to take.  After all, as Pickering phrases it, alternative engineering cultures can be seen as a “collective exploration of the nonmodern selfhood”, where new subjects in conjunction with new artefacts and, in tandem, new kinds of “odd institutions” are constructed [@Pickering2010a 200, 400].  The advantage of inquiring into hacker culture rather than cyberneticians is that it is possible to analyse collective practices rather than individual contributions, and ones that are formative of our current historical horizon.  *Notwithstanding the “social marginality” of hackers and the “hobbyist origins” of hacking [@Pickering2010a about cybernetics, 388], in the penultimate section I argue that hacker practices ground an anti-modern ethical relation to material agency framed by a symmetric ontology.*  However, first it is necessary to situate hacker practices historically in relation to the cybernetics movement.

![Logo of the Brussels Hackerspace](images/hsbxl-logo.png)

[^quotes]: For the same reason, I make use of no direct quotes, but simply recount pieces of hacker folklore on which a shared sense of identity rest.

# Figurations of cybernetics in the European hacker tradition

<!-- TODO rewrite second sentence -->

@Ross1990a identifies a shift in the expression of countercultural dissent in the decades following the 1960s.  He describes the ecologically-inspired anti-technology attitude of the hippies as the *technology of folklore*, contrasting it with the *folklore of technology* that inspired cyberculture – revolving around perseverance in a dystopian and oppressive world through technological expertise.  He does acknowledge that it is harder to read such new dissent politically.  Developing these doubts, @Markoff2005a and @Turner2006a focus on the cross-breeding of nascent cyberculture and Silicon Valley entrepreneurship – what @BarbrookCameron1995a called the *Californian ideology* or what @Curtis2011a blames directly on cybernetics.

Reactionary or not, as @Leary1994a vividly expresses, the translation happened through novel artefacts, knowledges and practices of the brain, which in pop culture meant mainly psychedelics.  Essentially, subjects became hollow objects to be crudely manipulated in a determinist fashion, while objects expressed a richer subjectivity in their non-determinism.  *Cyberpunk* – first as a sub-genre of science fiction and soon as a fully fledged subcultural phenomena – expressed such ontological ambiguity in the language of the gothic uncanny [@Grant1998a; @Cavallaro2000a; @Rapatzikou2004a; @Whatley2013a].  Despite the dystopian bent of cyberpunk imaginaries, hackers drew the conclusion that in case the underdogs can grasp new technologies faster than the powers that be, they can at least go out with a bang. [^Accelerationism]

As the “cyber-” prefix suggests, these advances were partly inspired by cybernetics, a transdisciplinary development in the sciences that was also organised around the ontological ambiguity of the brain as the instrumental locus of subjectivity.  Classic cybernetics was expressed in books such as *The Computer and the Brain* [@vonNeumann1958a] or *The Brain of the Firm* [@Beer1972a], and analysed in books such as the aforementioned *The Cybernetic Brain* [@Pickering2010a] or *The Mechanization of the Mind* [@Dupuy2000a].  Cybernetic theories gave a good basis for technological determinist arguments (“solutionism”): e.g. that social problems can be transformed *to* and eventually solved *as* technological problems.  In other words, that revolution can be engineered [@Soderberg2014a].  Most commentators, such as @Tiqqun2012a or @Dammbeck2003a draw dire conclusions from these notions, arguing that cybernetics grew into an overarching ideology justifying a more oppressive and exploitative society.  Such analysis is both profoundly true and necessary to address political problems of our times.  However, it takes for granted that there is a single unified essence of cybernetics, and all the originality of the cybernetic world view have been absorbed into the capitalist system.

On the other hand, Pickering singlehandedly advanced a more positive outlook based on an alternative reading of British cybernetics, picturing it as an antidote to modernity’s blind paths.  I suggest that the two readings – symmetric and asymmetric cybernetics [@Pickering2013a] – share an experience of subjectivity which is first and foremost an encounter with objectivity: human intentionality with the material unknown.  Their paths bifurcate in the moment of an ethical decision about how to handle the encounter.  To rephrase Ross Ashby’s remark on Clausewitz: “Who will adapt to who?” [@Pickering2010a 140].  Engineering in general, and computer science in particular, serve as fertile grounds for experimenting with the ethics and epistemology of such an encounter, in light of its ontological implications.  It makes sense that hackers, – as participants in an *alternative* engineering *subculture* – explored a different aspect of cybernetics than what has been absorbed into mainstream institutions.

The ambiguity of cybernetics and its close connection to computerised subcultures is aptly described by Christopher Kelty in an introduction to a special issue of Anthropological Quarterly on the topic:

> The “cybernetic-informatic consciousness” that he uses to link
> journalists and anthropologists together opens a door to understanding why
> computers and cultures are equally everywhere today – and maybe for some
> surprising reasons that have a lot to do with the mid-century successes of
> both cybernetics and anthropology. Cybernetics’ fortunes look a lot like
> culture’s – overused, diffuse, heavily critiqued, yet nonetheless compelling
> in their most rigorous forms. Cybernetics’ dissemination looks a lot like
> culture’s – taken up across nearly every discipline, attenuated by
> circulation, unpoliced by classic disciplinary modes of ownership and
> exclusion. [@Kelty2010b]

Indeed, there is consensus between scholars that cybernetics started as a scientific paradigm, but quickly disseminated into other spheres such as psychiatric practice [@Pickering2010a], the arts [@Reichardt1968a; @MacGregor2002a] and its own subsequent branches such as chaos theory.  Perhaps more than other cultural movements, the European hacker tradition incorporated motifs of cybernetics in its fabric, with a special emphasis on *chaos theory*.  The latter became the organising principle for an engineering subculture that – especially in Europe – grew up on the fringes. [^cyxtoo]  Since autonomist struggles ran out of steam in the 1970s [@SchultzeGross1997a; @Wright2002a; @Cuninghame2005a; @Geronimo2012a], the advent of chaos theory was perhaps the only and last hope for revolutionary change.  If a very small, but incredibly smart move can produce systemic change, then a hacker with a computer can save the world.  Another – less radical – interpretation invested its faith in the instability of systems where small changes can propel into phase changes pretty quickly.  The latter interpretation put the apparent stability of “the system” [^system] in perspective, and allowed for revolution by accident.  What is essential, however, is that both interpretations empowered marginal social actors [^actors] with much more freedom than what contemporary political ideologies (activist or not) or current systems theory (scientific or not) allowed.  In the era branded as the *Information Age* [@Kline2015a] ruled by Shannon’s statistical approach to communication, *noise* became the rallying cry of outsiders [@Menkman2011a; @Krapp2011a i-xx] – and as a corollary, positive feedback [^positive] the analogue to the revolutionary process [@Larsen2011a].  In a chaotic world, therefore, *adaptation* was the key for survival, resiliency and perseverance.

No other person represented such tendencies better than Wau Holland (Herwart Holland-Moritz).  In 1980s Germany he was as much a public intellectual as a public engineer, as much an educator as an inventor.  Underpinning his ideology about universal access to computers and networks, as well as the protection of private information and the free flow of public knowledge, were devices and practices as much as discourses [@Kulla2003a].  He founded the Chaos Computer Club to advance these causes and legitimise hacker practices.  In an incident that is now part of “German computer science folklore” [@WP:BTX] members wired 134,000 DMs to themselves and presented the pile of money to the press after the German postal service (which held a monopoly on home banking) refused to fix the security issues they reported in its BTX system [@Denker2014a].  They saw the broken implementation of encryption for online banking as a social problem, but authorities did not heed their advice.  Therefore, they had to *demonstrate* the problem in the long tradition of the *public experiment* [@BornBarry2013a]: creating an ontological theatre which not only represented or described, but actually *performed* the vulnerability of informatic systems.  As I argue later on, such formational experiences cemented hackers’ trust in practice and performance over theory and representation.  Soon, chaos theory figured in the name of what is now the largest and most influential hacker organisation on the continent:

> The Club was so named not because it set out to cause chaos but rather
> because one of the founders, Wau Holland, felt chaos theory offered the
> best explanation for how the world actually worked.  Dutch hacker and
> entrepreneur Rop Gonggrijp says the club is about “adapting to a world
> which is (and always has been) much more chaotic and non-deterministic than
> is often believed”. [@Brooke2011a]

The Club was founded on December 12, 1981 at a table belonging to Kommune 1, an emblematic site of the autonomist movement, suggesting both continuity with and departure from the ideas and practices of the extraparliamentary left [@CCC2009a; @Wunschick2015a].  Chaos theory came to be officially embraced in the hacker scene as an explanation of *how the world actually worked*.  In other words, an ontology, and one hinged on performance.  As Wau Holland explained, the goal was “Causing Chaos as a means to display asymmetrical practices of Surveillance and control” [@Kulla2003a 14]. [^kulla1]  The organisation of hackers was itself to function as an ontological theatre: a public display of a chaotic world.  “Hence the most personal manifestation of Chaos was the computer club of the same name, whose speakers persisted with nearly missionary fervor that there is no security, that it is nothing but a nice yet deceiving illusion” [@Kulla2003a 30]. [^kulla0]

Following the establishment of regular hacker meetings such as the yearly Chaos Communication Congress (now in its 33rd edition), the proliferation of shared machine shops ushered in a subsequent period of hacking.  These served as club houses for the hackers who – now legitimised by their official organisations and high-profile actions in the public interest – could organise publicly.  One of the first was c-base in 1995, continuing the ***c***ybernetics, “***c***yberpunk”, ***c***omputer associations.  However, the mainstream success of hackerspaces started with Metalab in Vienna, which was initially proposed as KyBase (“Cybernetic Base”) in 2005. [^Metalab] This was not an accident because the hacker group behind the idea was called Wiener Kybernetischer Kreis: a word play on the name of cybernetics founder Norbert Wiener, the name of the city (“Wien”), and the interdisciplinary Vienna Circle (“Wiener Kreis”) that played a decisive role in the intellectual trajectory of the twentieth century [@WP:Metalab; @Stadler2001a].  However, hackers decided that references to cybernetics were too obscure to draw a more diverse audience, and called their base Metalab instead.  Indeed, Metalab then provided the blueprint and inspiration for many subsequent hackerspaces [@BreAstera2008a 7, 68, 87].

Hackerspace Brussels (HSBXL) materialised in 2008, while hackerspaces were exploding in numbers.  Its identity also plays on Norbert Wiener, who is pictured in the logo wearing flicker glasses [@HSBXL:Metalab].  Flicker glasses are essentially sunglasses fitted with flashing LED lights on the inside that simulate the brain in specific patterns.  As Pickering acknowledges (419), they are descendants of British cybernetic artist and inventor Brion Gysin’s Dreamachine, which was a turning tube with holes along its surface, producing a similar effect thanks to internal illumination.  The invention was inspired by @Walter1963a, the book of a seminal British cybernetician.  It was built in collaboration with Ian Sommerville, a computer programmer and companion of Burroughs and other Beats.  Walter was the first to describe the psychological effects of flicker [“The Central Effects of Rhythmic Sensory Stimulation”; -@Walter1949a].  Later he commented on the commercial success of stroboscopes in discos to the effect that he should be paid a royalty [@Pickering2010a 78-83].  However, much like other cybernetic motifs, flicker arrived to European hackers through American mediation.  It was the San Francisco-based Mitch Altman who popularised remakes of the device in hacker circles [@Cornfield2013a].  He soon acquired a standing in the hackerspaces scene comparable to Wau Holland’s role earlier, spending much of the year travelling between hacker clubs, teaching soldering and electronics while spreading a DIY [^DIY] anti-military message.  The emblem of his teachings was the Tripglass, which participants could make at soldering workshops. [^Tripglass] One could go on recounting other instances of cybernetic figurations in European hacking [such as @Maxigas2015a 272-273], but let three examples suffice for demonstrating a pattern.

To summarise, in the 1950s and 1960s both hacking and cybernetics emerged from the socialisation and systematisation of Second World War techno-scientific advances, at a specific moment characterised by ample funds for base research (at least in the United States).  Notwithstanding their origins in the academic-military-industrial complex, they were closely intertwined with the countercultural movements that flourished in their wake [@Turner2006a].  As both tendencies show, the relationship between science and technology drew ever more close, yet it is fair to argue that cybernetics was articulated primarily as a scientific culture, while hacking as an engineering culture.

Throughout the 1970s and 1980s cybernetics – or at least chaos theory – provided a much needed explanation of how the world actually works to hackers, who acquired an identity as a movement and a self-image as the underdogs of engineering.  Semi-underground scenes have been formed, which often came into contact with larger social structures like the authorities or corporations [the state and capital, respectively; @Sterling1992a].  Especially in the European context, hackers started to reflect on their socio-political roles and responsibilities as renegade engineers [@Maxigas2012a].

By the 1990s and 2000s, prominent personalities and organisations in the European hacker tradition were at least aware of some classic cybernetic scientific figures, artefacts and theories.  Even if the translation of cybernetics into hacker culture has been very superficial, partial and fragmented, it remains that cybernetic motifs were woven into its fabric.  This is not to suggest that the structural similarities between the ontology enacted by Pickering’s cyberneticians and the ontology performed through hackers’ practices can be explained by a common genealogy.  The use of cybernetic imagery in hacker culture is not internally coherent, even if it’s presence is consistent.  For instance, where hackers champion chaos, their idol Norbert Wiener may champion order.  At least according to Klein, Wiener appeared to the average American as a humanist enemy of chaos:

> In his masterwork, *America as a Civilization* (1957), journalist and
> educator Max Lerner quoted Wiener’s idea that “communication is a dialogue
> between people united against the common enemy, whether we call it entropy
> or chaos.” It was one of the few popular references to Wiener’s extensive
> discussion of entropy in his books. [@Kline2015a 96]

Instead of a history of ideas, figurations of cybernetics (especially chaos theory) in European hacking amount to a *reconfiguration* of cultural historical imaginaries “that hold particular relations of persons and things – with land, or with information – in place” through a simultaneous reflexive and generative movement, including leakages and entanglements [@Suchman2012a 52, 58].  Cybernetic motifs *worked* for hackers, generating theoretical insights and practical results that both guided their understanding of themselves in the world, and helped to orient their technological endevours.  As I proceed to show in the next sections, everyday enactements of a cybernetic ontology are more deeply ingrained in hacker culture than a reflection on the scientific content or motives of cybernetics.

<!-- Notes -->

[^system]: Whether economic, political, technical or even world system.

[^actors]: Whether single individuals, small groups or subcultures.

[^kulla0]: “Der erste Hackangriff rief den Schutzpatron der Sicherheit auf den Plan, die Ordnung. Chaos as a counterpole to the patronsaint of security, order/system.”

[^kulla1]: “Chaos stiften als Mittel als Mittel der Sichtbarmachung von asymmetrischen Praktiken der Überwachung und Kontrolle.”

[^Accelerationism]: These ideas are not far from the arguments put forward by proponents of Left Accelerationism today [@SrnicekWilliams2015a].

[^cyxtoo]: Incidentally, European cybernetics likewise developed in relative social marginality compared to its US counterpart [@Pickering2010a 388].

[^positive]: The self-amplification of noise.

[^Metalab]: Metalab was formally founded the next year (2006).

[^DIY]: Do It Yourself.

[^Tripglass]: Later the Tripglass was replaced by the TV-B-Gone universal remote control that can turn off any television.  Mitch’s latest product is the Neurodreamer, a return to Gysin’s Dreamachine.

[^CCCM]: Chaos Computer Club München.

# Practices favouring practice

Before introducing engineering practices that are idiosyncratic to hacker scenes I would like to recount a scene that everyone can relate to.  An unspecified francophone hackerspace got flooded in June 2015 because the landlord repeatedly refused to fix the roof of the old factory.  Equipment was damaged and water covered a large part of the club.  A member proposed to drill a hole in the floor and sweep water down to the workshop of the landlord below.  The idea was adopted on a whim and since machine tools were stocked in the hackerspace, the hole was ready in a matter of minutes.  The hackers did not bring it up with the landlord, but he fixed the roof the next week.

What I find revealing about the incident is that members were “thinking” directly in material agencies and how to mobilise them, sidestepping institutions and symbolic communication between humans.  Just like in the case of the BTX, it was not enough to report vulnerabilities in the infrastructure: *hackers had to demonstrate them with a performance*.  Instead of talking, then, the hackers had to do something to get their point across.  Moreover, instead of mopping up the water, they accommodated its resistance by letting it continue its flow through the space.  In the course of the exercise, they entered a risky situation that could have gone in different unexpected ways, and they were ready to accept the consequences.  The most striking aspect for me, observing the scene, was how little discussion and hesitation went into it.  It was clear that I was immersed in a culture that favours practice over representation, and performance over cognition, ready to go where material agency takes the engineer.

The next subsections map out three alternative engineering practices that privilege practice more than the best practices of the industry.  Three cases may be sufficient – when laid out in relation to each other – to suggest a general pattern and illuminate the problem from different angles.  An additional example demonstrates how anti-modern engineering culture can translate into anti-modern organisational culture.

## Exploratory programming

According to researcher Keunwoo Lee (a computer scientist at the University of Washington), **exploratory programming** is about “programming by ’trying stuff out’ and seeing what happens” [-@Lee2004a].  It is a programming methodology taught in computer science and recommended for tackling problems that are not well understood.  For the same reason, it is ideal for learning by doing.  Since hackerspace members are not required to produce anything in particular, but often eager to learn, it is not surprising that exploratory programming is popular amongst them.  Compared to their counterparts with monolithic institutional backgrounds, programmers in hackerspaces tend to meddle into a higher number of programming languages, paradigms and problems.  While institutions tend towards a homogeneous technological infrastructure (set by a CTO for instance) and hire accordingly, experience with a particular technology or problem domain is not a criteria for hackerspace membership, only technical curiousity.  Just to follow the intricate jokes that Coleman pinpoints as the pinnacle of hacker culture, one has to know the basics of more than the most popular half dozen programming languages [@Coleman2012a].  Of course, once members actually start to build things in their favourite languages, some of those things become part of the infrastructure for running the space, at which point – like it or not – more members will have to know at least how to repair them.

Conversely, like any type of organisation, there *are* languages and platforms that hackerspaces tend towards (if to a lesser extent): Python and LISP dialects.  Python, because it does not contain major engineering mistakes like other popular programming languages and allows for a high level of reflection; and LISP, because of its widely appreciated engineering aesthetic and its status as the ultimate “programmable programming language”.  Reflection and programmability both support the exploratory programming paradigm because they allow programmers more opportunity to understand and change programming language behaviour.  Exploratory programming is most interesting when it is used to understand a particular property of the programming language itself, or even when it is loosely concentrated on a problem domain, rather than a particular real-world problem.  The methodology and its technical repertoire is designed to iterate over possible solutions and hopefully find new ones through the process.

Therefore, exploratory programming is a methodology to engage with the temporal emergence of material agency in order to find a way to approach a problem that was not obvious before.  Material agency in this context simply means that algorithms, languages and environments exhibit resistance in an analogous way to the physical reality that physicists face – and by extension, mechanical engineers too.  @Pickering1995a already recognises the materiality of human language and abstract theories, so this is but a small extension to the theory of resistance and accomodation.  For Pickering, the temporal emergence of material agency simply means that there is no way to know if something will work or not until it has been tried out in practice.  Even then, in case of failures it is impossible to know if there *is* a way to make it work.  Practices that respect the temporal emergence of material agency are distinguished by the possible range of consequences that the resistance of the material may have on the overall endevour.

Exploratory programming allows the programmer to answer to the unknown arising during programming by changing the entire orientation of the work, to the point where even the target problem can be changed.  Similar conclusions have been reached by scholars of Human-Computer Interaction.  @Lindell2014a is interested in the materiality of programming and craftsmanship in software development in the sense of @Sennett2009a.  His claim is that exploratory programming “mainly describes a conversation with the material”.  I return to the idea of the conversation as the central metaphor for ontological ethics in the penultimate section.

In the hackerspace of Budapest (the Hungarian Autonomous Center for Knowledge, alias H.A.C.K.) one Autumn afternoon I sat with several members around the table.  One of the best programmers of the space announced happily that he is ready with paid company work, so now it is time to start another side project.  After a few hours of intense work I asked him what is the new program about – what does it solve.  He answered that it is not possible to know yet.  I was astonished because he already wrote so much (Python) code.  It was as if he walked out in the wilderness without a destination.  He was building a kind of general system to programmatically parse web pages, but it was not clear yet what are the real world tasks for which it could be used more effectively than existing solutions.  This way of approaching a problem was very different from most average programming jobs, where coders are paid to implement a pre-written specification, or at least work with a client to build a good product incrementally.

It was close to some academic work where ideas are tried out and practical applications can wait.  Nonetheless, even academic researchers have to write a research proposal, get funding and conform to an institutionalised timeline, not to mention answer to superiors.  However, in this case there was no supervisor and no institutional framework, only a club created by hackers themselves to support tinkering with the material.  Conversely, the result would not be directly remunerated by anything other than the experience itself and perhaps the respect of peers.

While in most cases exploratory programming may not be so efficient as a less spontaneous software development methodology, it allows programmers to perform the part of their job closest to engagement with materiality: coding.  Negotiating the task, designing the software architecture, writing the documentation – and in most cases implementing a ready-made specification – are all part of the programmers’ job that exploratory programming puts less emphasis on.  While these activities arguably present their own resistances, it is not the resistance of the program code itself.  Hacker culture values engaging with the resistance of the program code itself over other tasks involved in programming.  As the hacker saying goes, “two hours of planning can save you two days of coding – but then again, two days of coding can save you from two hours of planning” (Personal communication, Ralf Bendrath, 2007-11-09).

## Penetration testing

**Penetration testing** is about probing a technological system in order to find faults in it.  It can be done with malicious intent, in which case it can be simply called hacking or cracking, but it can also be done under contract in order to improve security by reporting problems found during the test.  Thus, penetration testing can be thought of as an antonym of the scientific experiment: while in a classic scientific experiment the point is to create an isolated environment where a repeatable operation is carried out in order to prove a hypothesis, the point of penetration testing is that it takes place outside of the laboratory, carried out on actual infrastructure through means that are difficult to foresee, in order to find problems in practice.  For instance, banks are generally required to hire security companies to make sure that their systems are secure and their infrastructure conforms to the relevant industry standards (such as ISO/IEC 27002:2007, 21188:2006, etc.).  Many such companies are run by hackers.  Penetration testing can include anything from breaking into a computer network, through physical security like stealing paper documents from facilities or social engineering where the attacker talks their way to sensitive information.  However, these are related practices requiring a similar mindset, and here we focus on software security because it is the most widespread area of expertise in hackerspaces. [^lock]

My claim is that in order to work on penetration testing, one first has to accept that there is a gaping field to be explored between representation and performance.  While most programmers and administrators start out by assuming that the actual performance of a program is more or less accurately described in its specification (because they have to use it as a building block in their systems), penetration testers could not even start their work without assuming that the program actually behaves differently under certain circumstances.  It is those circumstances that the penetration tester is interested in, and most often they are to be found by trying out the application in a wide variety of ways, looking at typical mistakes and known flaws in its components.  However, the real prize of a penetration tester is to find accidental mistakes and previously undiscovered flaws in implementations.  If there is a way to compromise the system, it is called a *vulnerability* [^CVE].  Previously unknown vulnerabilities are called *zero days*, because vendors, developers and administrators have no opportunity to fix them.  They play an important part in hackers’ imaginaries, reputation and economies.

Vulnerabilities are effectively the (most lucrative) products of penetration testers.  Hackers construct vulnerabilities by engaging with the material resistance of an infrastructure, often through long time periods.  Therefore, vulnerabilities are a good example of temporal emergence.  A vulnerability report is often a mere description of a weakness, but eminent vulnerability reports also include *exploits*.  An exploit is a short piece of code that demonstrates the vulnerability by triggering it in practice.  Therefore, exploits can be used to compromise systems even by people who have only basic informatics knowledge. [^kiddies]  Exploits are also recognised for their exchange value and consequently brought and sold on the black market, or acquired legally by vendors through bug bounty programs, or even reported on public mailing lists by independent researchers (similarly to academic findings in scientific journals).

Exploits can be conceptualised as ontological theatres, which extort systems into strange performances.  “No system is secure” is a mantra of hackers and each vulnerability is an additional proof of this point.  Vulnerabilities are studied by hackers both for fun and profit.  Their entertainment value comes from the fact that they achieve some unusual, often seemingly impossible task – like gaining administration rights to a system without knowledge of the appropriate credentials.  The root of the vulnerability are the unintended consequences of the software written by developers, or the actions of the system administrators who run the vulnerable systems.  Since the consequences are unintended, most vulnerabilities are discovered by examining the performance of the systems in practice, rather than the underlying theories, even though the vulnerability may prove the theory behind the system flawed. [^backdoors] Therefore, a vulnerability is often theoretically impossible, and by definition unknown before its discovery.  The penetration tester have to be open to the unknown and do things that invite it to manifest itself.  There are penetration testing methodologies taught at universities, but searching for vulnerabilities remains a craft that requires a calling, rather than a routine procedure that can be described in manuals.

An ontological theatre does not only take advantage of a particular ontological outlook in its design, but also showcases it through its performance.  As a living proof that a system does not only work as advertised, but also in other “strange” ways, an exploit points to the distance between representation and performance.  Such a performance is “strange” because it goes beyond – and very often against – the way given system is supposed to work.  As such it also showcases and legitimises the epistemological advantages of working in close consideration of the cybernetic ontology.

<!-- TODO: Include a paragraph on CTFs at hacker conventions! -->

## Hardware hacking

Hardware hacking is arguably the *raison d’être* of hackerspaces [@KostakisNiarosGiotitsas2014a, @Dafermos2014a, @Maxigas2014n].  On the one hand, the rise of hardware hacking accentuated a need for hackers to join forces in clubs commanding their own real estate, because sharing the necessary manufacturing resources and tacit knowledges solely online is difficult.  On the other hand, once various strands of hackers came together in the same premises, working on tangible artefacts of *physical computing* [@IgoeOSullivan2004a] provided an opportunity for common engagement between enthusiasts of software, hardware, mechanics and more. [^multi]  Electronics classes – especially introduction to rapid prototyping tools such as the Arduino line of microcontroller boards – are usually amongst the first organised activities in newly founded hackerspaces.  Similarly, “Learn to solder” and “Soldering is easy” is the signature workshop and fanzine of the aforementioned hackerspaces personality Mitch Altman, who likes to give it in budding hackerspaces around the world.

<!-- [0. Motivation] -->

Hardware hacking can be conceptualised as the appropriation of more widely used rapid prototyping practices.  However, in the hackerspace context the name is somewhat of a misnomer since many a hardware hack is neither rapid nor a prototype.  Prototyping in an industry is typically practiced with an eye on developing a final product, or sometimes used in an academia to learn something specific.  Rapidity, when it is applied to prototyping, refers to the fact that desktop manufacturing technologies such as 3D printing and development tools such as programmable microcontrollers can be used to speed up design and implementation of hardware.

I argue that the appropriation of rapid prototyping practices in hackerspaces may be driven by a desire for engagement with material resistances and strange performances.  At the same time, it is enacted under specific material constraints answering to the wider structural constraints on hackerspaces.  Of course, both desires and constraints can be similar in certain institutional settings.  However, institutions ultimately adopt rapid prototyping as a means to an end, whether learning by doing, research and development, or straightforward product development.  Even if some workers are motivated by the encounter with the material resistances and strange performances during product development, most companies are constructed as an organisation geared towards making products.  Such is the modern relationship to technology – reflected in the discourse of *innovation*: instrumental rationality frames most organised engagements with technology.  As a counterpoint, I argue that in the organisational environment of hackerspaces, encountering material resistances and strange performances is not a means to an end but an end in itself.

<!-- [1. Material constraints: flotsam] -->

Hardware hacking is highly dependent on the components and manufacturing equipment that developers can get their hands on.  Ordering new components or acquiring funding is both cumbersome and boring.  Instead, hackerspaces traditionally include a junkyard of sorts that hackers scavenge for components.  Any project or product – assembled or not – can fall prey to rapid prototyping in a hackerspace.  Therefore, both purpose-made stickers (“Do Not Hack”) and ad-hoc notes (“Don’t Touch”) are used to distinguish *loot* from *work in progress* projects and *infrastructures* that are essential for operating the space.  Members have lockers or boxes to keep their stuff away from prying hands. [^dnh]

Hackerspaces are filled with the technological refuse of latter generations, to the point where several of them collect typewriters (used by typewriting clubs at Noisebridge, San Francisco or at Technologia Incognita,  Amsterdam that meet regularly at the premises) and operate museums of working computers (for instance at Arnhem, The Netherlands or in Catania, Sicily).  In turn, obsolete machine tools from factories and legacy laboratory equipment are sometimes dropped at hackerspaces.  Technical solutions, design insights and salvaged components from these machines may become building blocks of prototypes.  Constraints on hardware building such as using readily available components and manufacturing tools can be interpreted as another form of material agency that plays its part in hardware hacking and emerges both historically and stochastically.  Like the ontological theatres of the classic cyberneticians, a prototype made in a hackerspace often showcases an idea or an enigma, an intervention whose actual engineering could be deceptively simple or primitive – or its practical value questionable.

Returning to Coleman’s point that sophisticated in-jokes are the heart and soul of hacker culture, it can be argued that prototypes are often not more than elaborate practical jokes, a running commentary on the absurdity of rational instrumentalisation in modern technologies.  A case in point is the common trick implemented in hackerspaces, where step-motors (of a 3D printer, laser cutter or even a stack of old CD-ROM drives) are used to generate evocative of popular classical music, such as the Empire theme from Star Wars.  Rather than accomplishing a practical task, such contraptions function as ontological theatres showcasing strange performances of otherwise familiar machines.

When @Latour2008a writes about the virtues of design thinking as an amodern form of thought, he emphasises that design always starts with something which is already there.  Therefore, design is always redesign.  For Latour, this is in opposition to the Promethean hubris of modernity where the inventor is supposed to create ex nihilo.  Latour praises the careful humility of design which never starts from scratch, but shapes things attentive to the circumstances.  However, it is curious that it never occured to the author of *We Have Never Been Modern* that Prometheus actually stole the fire rather than invented it.  The fire was already there, what happened is that it was made public.  Nonetheless, Latour’s description sits well with rapid prototyping, which starts from the material available at hand, strives to create a functioning thing as soon as possible, and tinker on from there, rejecting  “’destroy it all and build something completely different’ modernism” [@Flynn2014a].

<!-- [2. Tinkering] -->

What is carried on in the translation of rapid prototyping into hardware hacking is the conviction that practice, not theory – materials, not blueprints – should guide development.  The ontological commitment necessary for pursuing development in this way is to a world that is not infinitely knowable through what Pickering calls “positive knowledge” (a staple of modernity, see 2010, 401).  In other words, there is no way to know how a prototype will turn out.  Therefore, prototypes are built not only rapidly but in quick succession, so that every iteration can build on the practical experience gained.  In the connected world of hackerspaces this often means reproducing something that was done elsewhere, often with personal help from the previous designer.  Due to the haphazard source materials and other local factors, exact copies are downright impossible.  Moreover, it is widely acknowledged that as long as the experience is new to a participant and not a routine task, rebuilding something old can be as rewarding a journey as building something new.

<!-- [3. Uncertain futures] -->

Education, research and production in hackerspaces are mere corollaries to encounters with material agency that produce unpredictable effects.  The irrelevance of the very categories that define modern institutions is demonstrated in how seamlessly they can blend into each other in the quotidian life of the hackerspace.  In particular, prototypes made in hackerspaces often evade these modern categories of instrumentalisation.  It may not be clear whether they are prototypes of personal projects, learning exercises, artworks, commercial products or activist interventions.  Indeed, the very hackers working on the project are often altogether uninterested in such questions.  At some point the project may be abandoned, nailed to the wall of the hackerspace as an example of how to (or how *not* to) connect two specific electronic components – or it could become an activist intervention in a political debate, but just as well provide the basis for a lucrative startup.  These destinies matter little when the point of the process is to encounter the unknown on a common ground.

[^multi]: Building hardware always already includes software engineering (for interfaces and especially the firmware) and mechanics (for the tangible components, especially robotics actuators).

[^dnh]: From the Code of Conduct draft of the Xinchejian Hackerspace in Shanghai: “DO NOT HACK means DO NOT HACK If you’re leaving something and you would rather it was not hacked, please label it with a DO NOT HACK notice. If you see something has a DO NOT HACK notice on, don’t hack it” [@Xinchejian2013a]. For other examples, see @Juul2010a.

# Odd institutions hosting strange performances



<!-- TODO: compose this chapter to be consistent! -->

<!-- TODO: introduction (just a few short sentences) -->

<!-- ## Experiments: From the rapid prototyping section -->

Both @Pickering2010a and @Dupuy2000a pay special attention to the changing role of the experiment and models (respectively) in cybernetic research.  They argue that one result of the shifting ontological orientation of cyberneticians was a corresponding change in what counted as an experiment in scientific practice.  *Modern* experiments aim for a reproducible environment where ideally only one variable is changed at any one time – a tradition rooted in the work of the 16th century philosopher Sir Francis Bacon.  Cyberneticians, however, came to terms with a more messy experience of the world.  *In vivo* experiments happened in direct interaction with matter under real life conditions.  Therefore the meaning and content of scientific experiments came closer to the everyday usage of the word.  Interaction with what cyberneticians called *complex systems* (such as Gray Walter’s tortoises, Ross Ashby’s homeostatic setups or Stafford Beer’s pond) required researchers to make interventions in processes they could not fully model.  As @CantwellSmith2010age argues, cybernetics can be seen as an answer to a crisis of modernity, where researchers faced phenomena which was deterministic but not predictable – two properties which went hand in hand in previous research. [^evol] It is exactly this aspect of cybernetic research which was developed in its offspring, chaos theory, and which figures prominently in the hacker tradition.

## Technological Debris: From the rapid prototyping section

The “lack of material and social discipline” is the double thread that ties together the trio of ontological theatres emblematic of UK cybernetics: Grey Walter’s tortoises, Ross Ashby’s homeostats and Gordon Pask’s Musicolour [@Pickering2010a 324].  First, they were constructed from the junk left over after the Second World War: surplus bomb relays from the RAF and obsolete telephone relays from the Post Office.  “Elizabeth Pask (n.d.) recalled that Gordon and Harry Moore built Musicolour from ’old relays and uniselectors junked from post office telephone exchanges’ – the same components that Walter and Ashby used in their model brains” (Ibid.). [^relic] In fact, cybernetics itself was largely a product of synthesising the theoretical and practical legacy of the war effort coming “out of the detritus of war and a technological society” (Ibid.).  But what is more crucial for the present argument is that the design and implementation of these artefacts was shaped by the technological debris of the time.

## Side projects and amateurism: From the rapid prototyping section

Socially, UK cyberneticians pursued cybernetics as a side project barely (if at all) tolerated by their respective institutions and hardly fitting into their respective disciplines.  “I am struck, first, by the profound amateurism of British cybernetics.  Key contributions often had an almost hobbyist character: Walter built his first tortoises at home in his spare time; so did Ashby his homeostat (at least, in the apocryphal version of the story); likewise Beer and Pask’s experimentation […]. Cybernetics welled up outside the usual channels, and it found little support within those channels” [@Pickering2010a 10]. [^kitchen]

## Tinkering: From the rapid prototyping section

As Even if the results of British cybernetics have been distilled into (pseudo-)scientific books and articles, how the substance of the work was carried out was nothing short of tinkering with engineering in a largely peripherial setting.  Needless to note, these characteristics neatly describe the hackerspaces of today, especially as the sites of hardware hacking and rapid prototyping.

## Marginal institutions: From the rapid prototyping section

Hackerspaces are likewise marginal institutions, with the crucial difference that they were explicitly constructed to inhabit marginality as a countercultural position.  For some of them social marginality was a natural position – for others it became a necessity.  Either way, @ColemanGolub2008a notes that repression as an outside pressure was instrumental for the organisation of the hacker scene and for forging a compact set of ideas and practices that hackers held their own.  They had to realise soon enough that their exploits and out of the box engineering culture goes beyond the confines of modern institutions, so they banded together to pursue an alternative trajectory.  Consequently, hacking is today a popular folk tradition, which developed a relatively wide social basis.  As a result, hackers can rely on their own infrastructure such as the hackerspaces, and using that same legitimacy, they can even get what they want from institutions too, in case it is really necessary.

# From cybernetic ontologies to hacker ethics

Ethics mediates between ontology and practice.  Therefore, eliciting the ethical consequences of the view of the world distilled in the cybernetic ontology can further illuminate the practices described in the previous section while preparing the ground for the political conclusions in the next section.  Departing from @Pickering2010a, I theorise the ethical consequences of the cybernetic ontology by way of the ontological ethics of Emmanuel Lévinas [-@Levinas1969a].

The starting point of Lévinas’ ontological ethics is a Hegelian understanding of the Other as an existential threat to the phenomenological subject.  The threat comes from the ambiguity of the Other between being another agent like me, but also fundamentally different.  The proposed eminent ethical relationship with the Other is modelled on the conversation.  In short, the conversation allows for keeping a distance and therefore recognising difference, while at the same time exposing oneself and therefore be effected by the relationship.  The conversation does not seek to destroy or assimilate the Other, but to learn and adapt to it.  There are obvious parallels here with the Conversation Theory developed by the classic cybernetician Gordon Pask [-@Pask1976a].  Moreover, both authors conceptualised the conversation as not necessarily verbal, leaving theories open for performative interpretations.  However, in order to illuminate the ethical relation to the Other, Lévinas uses further timely metaphors such as hosting the other in my home, but also falling hostage to the Other in a foreign land.

My suggestion is that this formulation of ontological ethics is descriptive of hackers’ relationship to material agency found in their interactions with machines.  In line with the argumentation about the unstable ontological divide between subjects and objects that is expressed in cyberpunk works, the Other takes an objective form in these experiences.  While certainly a departure from Lévinas original thought, I hope that the recognition of the Other as the material agency performed by objects explains many aspects of symmetric cybernetics as well as hacker culture.

Pickering recounts how Ashby’s prolonged struggle with prototyping DAMS made him abandon “the modern engineering paradigm of knowledge-based design in favor of evolutionary tinkering” [-@Pickering2010a 128] that “necessarily entailed a degree of *respect* for the other” [-@Pickering2010a 32].  Thus, his desperation marked the ethical moment in cybernetics, and resonates well with hackers’ difficulties.  On closer examination, each of the practices above share a few characteristics that point to such a realisation.  All have to do with the recognition of material agency in the form of bugs, or glitches in computer science.  It is not hard to recognise that the resistance of the material manifests itself as a bug or glitch in the technological system.

First, the creation of situations in which bugs can occur and unfold.  Since bugs are the products of penetration testing, it is no wonder that security experts have mastered the art of summoning errors through unexpected inputs into the system.  Do-ocracy as an organisational form is also open to bugs, since it is considered essential for members to be comfortable making mistakes.  Second, accommodation but not recuperation of bugs into the development process.  Exploratory programming is about meeting the full force of the problem in the very spontaneity of practice rather than solving it first theoretically.  In hardware hacking each iteration of a prototype has serious design flaws – since this is exactly what distinguishes it from a finished product. [^protoproduct]  Third, bugs resulting in unforeseen, and thus potentially unexpected and potentially dangerous results.  I would like to emphasise once again the exploratory nature of drilling a whole on your floor (which is the ceiling of your landlord).  It is hard to argue that it is a safe approach to conflict resolution.  The strength of the gesture is not in finding a safe solution but on the contrary: opening up the possibility of an unexpected, if dangerous solution to work out or not.

The moral of the story is that bugs function analogously to Lévinas’ Other in the diagram of the hackers’ engineering culture.  Once this assertion is secured, the consistency of the practices above is apparent, as well as the common ground of politics that grows out of such practices.  The unknown is sought out for the experience of the encounter and material agency is accommodated, but not recuperated into the engineering enterprises of hackers.  Furthermore, as I argue in the next section, the organisational infrastructures of the scene are built to accommodate such an ethical relation with the unknown – unlike modern institutions.

<!-- Notes -->

<!-- Examples cited above are mixed according to this table: -->
<!-- * Hole 3 -->
<!-- * Live coding 2 -->
<!-- * Exploratory programming 3 -->
<!-- * Penetration testing 1 -->
<!-- * Rapid prototyping 2 -->
<!-- * Do-ocracy 1 -->

[^protoproduct]: Indeed, debugging the prototype to get an actual product is most often more difficult and definitely more tiresome than developing an almost perfect prototype.

# Conclusion

## Anti-modern techno-science society

Finally, we are in a position to ask the crucial question: how does the hackers’ world view – through practices developed on top of it – challenge modernity?  Latour’s [-@Latour1993a] point that modernity has always been more discourse than practice, especially since in practice it never actually worked, is convincing.  However, such a realisation alone does not make modernity go away.  As Latour himself advocated in his works since, culture and institutions have to be reinvented and rebuilt so that they are not conditioned by disastrous modern myths.  Hence, the most significant contribution of hackers to the project of surpassing modernity may well be establishing popular genres of engineering and setting up organisations that are constructed in a way that points beyond the modern view of the world.  A kaleidoscopic overview such as this article can identify patterns that are worth exploring but does little in way of arguing concrete cases.  Further studies are needed to understand the historical trajectory, ontological sensibilities, and social content of these practices and how they come together in innovative organisational forms such as the hackerspaces.

* * *

Having said that, it is already clear that hacker practices treated here differ from those proposed by Pickering in three major ways.  First, **hacking is anti-modern** since it is deliberately articulated in opposition to modern practices.  Hackers – even powerful ones – have always positioned themselves on the periphery of modern society and regarded their movement as an anomaly – even if an inevitable one.  The practices above have each been developed in diametrical opposition to industry best practices of mainstream engineering.  A single example would be penetration testing which is part of the *offensive security* tradition, which challenged assumptions that building a secure system according to specifications is sufficient for resilience, advocating that all security experts have to be familiar with the mindsets, skill sets and toolsets of attackers.[^critiques]

Second, ***hackers can reproduce their social basis*** through an expanding network of hackerspaces, periodic meetings and online communities.  While classic cybernetics revolved around the cyberneticians themselves, hacking is organised around practices which can be appropriated by anybody.  In that sense hacking is like popular culture: contained in and communicated through genres.  Classic cybernetics did practice and propose organisational innovations from the dinner societies of the UK cyberneticians through Kingsley Hall and Archway communities to the Fun Palace.  However, scenes of hackers have been arguably more innovative, more concentrated and more successful in organisational innovations.  From the early underground phreaking groups which organised on telephone networks through hacker clubs and meetings which aggregated hackers through the recent proliferation of hackerspaces that provide physical premises public access, hackers found different ways to reproduce their culture and pass it on to the subsequent generations.  Indeed, one may say that hackers are more concentrated on perpetuating their folk culture than classic cyberneticians were.

These differences in the constitution of a techno-scientific culture must have contributed to the differences in their trajectories.  As Pickering emphasises again and again, cybernetics failed to reproduce its social basis, which means building the institutions that can sustain its culture throughout generations.  Moreover, while classic cybernetics is somewhat of a historical relic, hacking at this historical moment may experience its heyday.  Hacking is currently expanding to incorporate diverse problem domains (such as biology or gastronomy) and audiences (such as managers or children).  Hacklabs are being set up by corporations and governments, so that one might speak about the hackerisation of everything.  Since hacking developed as a challenge to modern institutions, it was clear from the beginning that it can only flourish through inventing new forms of organisation, new forms of work and new forms of life sustaining its engineering ethos.

Third, ***hacker culture is organised around engineering***, while the cybernetic ontology was originally articulated as a scientific culture.  Of course, since both point beyond modern categories, both disseminated quickly into the most diverse areas, even if retaining a heartland in science or engineering, respectively.  In fact it could be argued that the decline of classic cybernetics and the rise of hacker culture are both embedded in a larger process, where engineering is becoming hegemonic not just in its relation to science but many more areas of social life.

[^critiques]: Another evaluation of exploratory programming by scientists is from @Bundy2009a 37: *“This exploratory programming methodology has been the target of much criticism of AI, especially from the theoretical computer science community. There are elements of both justice and unfairness in this criticism. Such an *ad hoc* methodology is no way to develop a robust program. It is the antithesis of the structured programming and formal methods advocated by software engineers.”*

* * *

Throughout the article I pick up practices strategically where the cybernetic ontology manifests in hacker practices as ontological theatres (showcasing another way of approaching material agency).  Notwithstanding such selective bias, I believe that a similar outlook is present, albeit in a much more diluted form, in many areas of hacker culture.  The deep hacker studies research program is grounded in the hypothesis that the sociological implications of such ontological beliefs – perhaps mediated by an ethical regime – can help to understand specific areas where hackers made contributions.  For instance, the disruptive effects of practices as disparate as hacktivism, online piracy, digital fabrication or free software may find a common vector of explanation in ontological analysis.  On a final note, I argued that hackers’ efforts to research and organise in close consideration of an anti-modern view of the world – the socialisation of cybernetics, if you like – spawned a vibrant popular culture with wide implications for technology, science and society.

\newpage

# References


