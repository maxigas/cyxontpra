% Cybernetics, Ontology, Practice: Anti-Modern TechnoScience in the European Hacker Tradition
% Maxigas
% Draft 1

![FIXME](images/xkcd.png)

# Introduction: The case for deep hacker studies

Hacker artefacts, knowledges, practices and scenes constitute an alternative engineering culture that can be characterised as anti-modern technoscience.  Stemming from a break in the 1960s cultural schock [@Wallerstein2004a], hackers’ relationship to technology rests on an approach related to the cybernetic ontology identified by @Pickering2010a and articulated in the sciences by cyberneticians.  Such an approach privileges practice over representation, performance over cognition and adaptive encounters with the unknown over the domination of Nature.  In short, it is informed and forged by an experience in the ontology of becoming.

While it has been argued that even engineers and scientists who work in the heart of modern institutions grapple with the mangle of practice in their daily routines [@Pickering1995a], it has also been pointed out that neither official accounts of engineering or scientific work, nor the institutions that frame them are necessarily constructed according to such realisations.  @Pickering2010a brought a historiography of scientists (the cyberneticians) who attempted to reformulate scientific tools, theories, practices and institutions to match their experiences in the ontology of becoming.  Starting from some genealogical threads on the appropriation of cybernetics by hackers, I argue here that antimodern technoscience can be shown to be at work in our contemporary historical horizon.  Once again, rather than claiming that hackers work with an ontologically different technology than mainstream engineers, what I seek to demonstrate is that *ontology matters* as part of culture.

Doing so I follow the classic SCOT approach as far as I assume a methodological relativism which is not concerned with the ontology of technology per se.  Rather, it is concerned with the technological frames that different social groups construct differently.  At the same time, I seek to extend the SCOT approach by making the social consequences of the ontological experience lived by a particular social group the centre of the investigation.  In other words, the ontological tools, conceptions and experiences of practitioners guide how they construct technological frames.  Studying hackers offers lessons on how artefacts, knowledges, practices and even organisations can be different when the mangle of practice is taken into account in a more consistent and coherent manner.

<!--     A collective exploration of the nonmodern selfhood. → *New kinds of -->
<!--     people* emerge, beyond the modern self. -->

<!-- articulated [practices] -->

<!-- ontological theatres and strange performances -->

<!-- @Latour -->

<!-- @Bijker2009a  -->

<!-- Ontological assumption in the everyday  -->

<!-- A point of caution [limitations] -->

As Pickering in researching UK cyberneticians, I am more interested in how to live and how to engineer in a different way than to capture the essence or the statistical veracity of hackerdom.  The wealth of the empirical material – as the title suggest – is drawn from the European hacker tradition, but I do not claim that it captures the mainstream of hacking on the continent.^[Or even that it is restricted to the continent – indeed, some of the empirical material below takes the reader overseas, thanks to the interconnected circuits of hacker culture.]  I would rather like to highlight a stream of motifs that is theoretically revealing.  Everything that is laid down here is taken from my decade long anthropological and historical research into hackerspaces, but this time the ambition is not ethnological documentation.  On the contrary, it is to explore the relationship between philosophical-ontological attitudes formed between people and their machines and their role in shaping practice.^[For the same reason, I make use of no direct quotes, but simply recount pieces of “hacker lore” on which shared sense of identity rest.]  In more general terms: what happens when engineers think about the world in a different way?

# Figurations of cybernetics in the European hacker tradition

@Ross1990a identifies a shift in the expression of countercultural dissent in the decades following the 1960s.  He uses the turns of phrase *technology of folklore* to describe the ecologically-inspired anti-technology attitude of hippies with the *folklore of technology* about perseverance in a dystopian and oppressive world with through technological expertise, adopted by hackers.  He does acknowledge that it is harder to read such new dissent politically.  Developing these doubts, @Markoff2005a and @Turner2006a focuses on the cross-breeding of nascent cyberculture and Silicon Valley entrepenuership – what @BarbrookCameron1995a called the *Californian ideology* or what @Curtis2011a blames directly on cybernetics).

Reactionary or not, as @Leary1994a vividly expresses, the translation happened through novel artefacts, knowledges and practices of the brain, which in pop culture meant mainly psychedelics.  Essentially, subjects become hollow objects to be crudely manipulated in a determinist fashion, while objects expressed a richer subjectivity in their nondeterminism.  *Cyberpunk* – first as a subgenre of Science Fiction and soon as a fully fledged subcultural phenomena – expressed such ontological ambiguity in the language of the gothic uncanny.  Despite the dystopian bent of cyberpunk imaginaries, hackers drew the conclusion that in case the underdogs can grasp new technologies faster than the powers that be, they can at least go out with a bang.  ^[These ideas are not far from current intellectual fashion of Accelerationism.]

As the “cyber-” prefix suggests, these advances were grounded in cybernetics, a transdisciplinary development in the sciences that was also organised around the ontological ambiguity of the brain as the instrumental locus of subjectivity.  Classic cybernetics was expressed in books such as *The Computer and the Brain* [@vonNeumann1958a] or *The Brain of the Firm* [@Beer1972a], and analysed in books such as the aforementioned *The Cybernetic Brain* [@Pickering2010a] or *The Mechanization of the Mind* [@Dupuy2000a].  These theories gave a good basis for technological determinist arguments of solutionism: e.g. that social problems can be transformed and eventually solved as technological problems – or in other words that revolution can be engineered.  Most commentators such as @Tiqqun2012a or @Dammbeck2003a draw dire conclusions from such a way thinking, arguing that it became an overarching ideology that justified a more opressive and expoitative society.  On the other hand, Pickering singlehandedly advanced a more positive outlook based on an alternative reading of British cybernetics, picturing it as an antidote to modernity’s blind paths.  I suggest that the two – symmetric and assymetric cybernetics – can be reconciled on the grounds that they experience subjectivity first and foremost as an encounter with objectivity: human intentionality with the material unknown.  Their paths bifurcate in the moment of an ethical decision about how to handle the situation.  To reformulate Ross Ashby: “Who will adapt to who?” [@Pickering2010a 140].  Engineering in general and computer science in particular serve as fertile grounds for experimenting with the ethics and epistemology of such an encounter, as much as its ontological implications.

The ambiguity of cybernetics and its close connection to computerised subcultures is aptly described by Christopher Kelty in an introduction to a special issue of Anthropological Quarterly on the topic:

> The “cybernetic-informatic consciousness” that he uses to link
> journalists and anthropologists together opens a door to understanding why
> computers and cultures are equally everywhere today – and maybe for some
> surprising reasons that have a lot to do with the mid-century successes of
> both cybernetics and anthropology. Cybernetics’ fortunes look a lot like
> culture’s – overused, diffuse, heavily critiqued, yet nonetheless compelling
> in their most rigorous forms. Cybernetics’ dissemination looks a lot like
> culture’s – taken up across nearly every discipline, attenuated by
> circulation, unpoliced by classic disciplinary modes of ownership and
> exclusion. [@Kelty2010b]

Indeed, there is consensus between scholars that cybernetics started as a scientific paradigm, but quickly disseminated into other spheres such as psychological practice [@Pickering2010a], the arts [@Reichardt1968a; @MacGregor2002a] and its own subsequent branches such as chaos theory.  Perhaps more than other cultural movements, the European hacker tradition incorporated motifs of cybernetics in its fabric, with a special emphasis *chaos theory*.  The latter became a sort of rallying cry for an engineering subculture that – especially in Europe – grew up on the fringes.  Since  autonomist struggles ran out of stream in the 1970s, the advent of chaos theory was sort of the only and last hope for revolutionary change: if a very small but incredibly smart move can produce systemic change, then a hacker with a computer can save the world.  Another – less radical – interpretation simply invested its faith in the instability of systems where small changes can propel into phase changes pretty quickly.  The latter interpretation put the existing “system” in perspective and allowed for revolution by accident.  What is essential, however, is that both interpretations empowered individual actors^[Whether single individuals or small groups.] with much more freedom than what contemporary political ideologies (activist or not) or current systems theory (scientific or not) allowed.  In the era branded as the *Information Age* [@Kline2015a] ruled by Shannon’s statistical approach to communication, *noise* become the rallying cry of outsiders – and negative feedback^[The self-amplification of noise.] the analogue to the revolutionary process [@Yuill2008a].  In a chaotic world, *adaptation* was the key for survival, resiliency and perseverance.

No other person represented such tendencies better than Wau Holland.  He was as much a public intellectual as a public engineer, as much an educator as a developer.  Underpinning his ideology about universal access to computers and networks, as well as the protection of private information and the free flow of public knowledge, were devices and practices as much as discourses.  He founded the Chaos Computer Club to advance these causes and legitimise hacker practices.  In an incident that is now part of “German computer science folklore” [@WP:BTX] members wired DM 134,000 to themselves and presented the pile of money to the press after the German postal service (which held a monopoly over the service) refused to fix the security issues they reported.  As I argue later on, such formational experiences cemented hackers’ trust in practice and performance over theory and representation.  What is important now is how Chaos theory figures in the name of the largest and most influential hacker organisation on the continent:

> The Club was so named not because it set out to cause chaos but rather
> because one of the founders, Wau Holland, felt chaos theory offered the
> best explanation for how the world actually worked.  Dutch hacker and
> entrepreneur Rop Gonggrijp says the club is about “adapting to a world
> which is (and always has been) much more chaotic and non-deterministic than
> is often believed”. @Brooke2011a

Following the establishment of regular hacker meetings such as the yearly Chaos Communication Congress (now in its 32nd edition), a new period of hacking was signalled by the establishment of shared machine shops.  These served as club houses for the hackers who now organised publicly.  One of the first was c-base in 1995, continuing the *c*ybernetics, “*c*yber-”, *c*omputer associations.  However, the mainstream success of hackerspaces started with Metalab in Vienna, which was initially proposed as KyBase (“Cybernetic Base”) in 2005.^[Metalab was formally founded the next year, in 2006.] This was not an accident because the hacker club behind the idea was called Wiener Kybernetischer Kreis: a word play on the name of cybernetics founder Norbert Wiener, the name of the city (“Wien”), and the interdisciplinary Vienna Circle (“Wiener Kreis”) [@WP:Metalab].  However, hackers decided that cybernetics was too obscure to draw a more diverse audience, and called their base Metalab instead.  Metalab provided the blueprint and inspiration for many subsequent hackerspaces [@BreAstera2008a].

Hackerspace Brussels (HSBXL) materialised in 2008 at the height of the hackerspace movement.  Its identity also plays on Norbert Wiener [@HSBXL:Metalab] who is pictured in the logo wearing flicker glasses.  Flicker glasses are basically sunglasses equipped with flashing LED lights on the inside, producing a distinct visual effect to be enjoyed by the wearer.  As Pickering acknowledges (419), they are descendants of cybernetic artist and inventor Brion Gysin’s Dreamachine, which was a turning tube with holes along its surface producing a similar effect thanks to internal illumination.  British cybernetician Grey Walter’s book The Living Brain served as the inspiration to the invention, and it was built with the help of Ian Sommerville, a computer programmer and collaborator of Burroughs and other Beats.  Indeed, British cybernetician Grey Walter was the first to describe the psychological effects of flicker [“The Central Effects of Rhythmic Sensory Stimulation”; @Walter1949a], and later commented on the commercial success of stroboscopes in discos that he should be paid a royalty (78-83).  However, much as other cybernetic motifs, flicker arrived to European hackers through American mediation.  It was the San Francisco-based Mitch Altman who popularised remakes of the device in hacker/maker circles [@Cornfield2013a].  He soon acquired a significance comparable to Wau Holland in the hackerspaces scene, spending much of the year travelling from hackerspace to hackerspace, teaching people to solder and work with electronics while spreading a DIY antimilitary message.  And the emblem of his teachings was the Tripglass, which participants could make at soldering workshops.^[Later the Tripglass was replaced by the TV-B-Gone universal remote control.  Mitch’s latest product is the Neurodreamer, a return to Gysin’s Dreamachine.]

Closer to where this volume has been conceived and prepared – in the hackerspace of München called μCCC^[München Chaos Computer Club.] – members prepared an electronic name tag for the 2011 Chaos Communication Camp in the summer.  The event is organised every four years as the biggest and most significant outdoor meeting of hackers on the continent.  American hacker conferences already featured electronic name tags, but the idea of German hackers was to make an artefact that can be useful after the conference too.  I analysed in my doctoral dissertation [@Maxigas2015p] how they sought to gather everything that is significant about hacker culture into a single object that would be given to all participants at the gathering, creating a sort of encyclopedia of the scene.  The artefact thus became a small computer with a screen, joystick and peer-to-peer wireless features: an open hardware analogue of the mobile phone.  It was still a major attraction at the annual Chaos Communication Congress at the end of the year in Berlin too, where the group experimented with its wireless tracking capabilities.  In order to demonstrate the potential of the artefact, its makers decided to devote the second part of their presentation of the project to an experiment.

The experiment replicated a scene from Adam Curtis’ documentary series on cybernetics released earlier that year: *All Watched Over by Machines of Loving Grace*.  In the opening sequence of the second part, Californian entrepeneurs FIXME and FIXME retell an experiment they made while archive footage of the occassion is shown.  Participants in a cinema setup were seated in front of a huge screen and given rackets without explanation.  The rackets were green on one side and red on the other – as in ping-pong.  The popular arcade game Pong appeared on the central screen.  Participants soon realised that they could control the paddles.  People on the right rows controlled the right paddle and people on the left rows the left paddle.  If enough people on a particular side showed up red rackets, the corresponding paddle moved upwards.  In order to reach the top of the screen, however, everybody on that side had to show a red paddle: there had to be a consensus.

The original organisers and the filmmaker agreed that the experiment demonstrated real-time, spontaneous, emergent social order taking advantage of coordination between a large number of participants using ICTs.  The key observation was that social order can be established without deliberation: it is enough if participants have statistical information abot the free choices of others.  Curtis points out that this is a justification for a technologically enhanced free market as the medium of social peace.  The Californian ideology proceeded on this course. 

Of course the use of cybernetic imagery in hacker culture is not internally coherent, even if it’s presence is consistent.  For instance, where hackers champion chaos, their idol Norbert Wiener may champion order.  At least according to Klein, Wiener appeared to the average American as a humanist enemy of chaos:

> In his masterwork, America as a Civilization (1957), journalist and
> educator Max Lerner quoted Wiener’s idea that “communication is a dialogue
> between people united against the common enemy, whether we call it entropy
> or chaos.” It was one of the few popular references to Wiener’s extensive
> discussion of entropy in his books. [@Kline2015a 96]

So far we have only dealt with figurations of cybernetics in what anthropologists call the symbolic: signs, names, significant objects and rituals.  But 

# Practices favouring practice

Before introducing practices that are idiosyncratic to hacker scenes I would like to recount a scene that everybody can relate to.  It actually happened in Canada, even though the main agent was a French hacker.  A hackerspace got flooded because the landlord repeatedly refused to fix the roof of the old factory where the club was.  Equipment was damaged and water covered a large part of the club.  A member proposed to dig a hole in the floor of the hackerspace and sweep all the water down to the workshop of the landlord, located right below.  The idea was accepted on a whim and since machine tools were stocked in the hackerspace the hole was ready in no time.  The hackers did not talk to the landlord about it but he fixed the roof the next week.

What I find revealing about the incident is that members were thinking directly in material agencies and how to mobilise them, sidestepping institutions and symbolic communication between humans.  Just like in the case of the Bildschirmtext, it was not enough to report vulnerabilities in the infrastructure: hackers had to demonstrate them with a performance.  Instead of talking, then, the hackers had to do something to get their point across.  Moreover, instead of mopping up the water or blocking its way by fixing the roof themselves, they adopted to its challenge by letting it flow through their space.  In the course of the exercise, they entered a risky situation that could have gone in different ways, being ready to accept the consequences.  The most striking aspect for me, observing the scene, was how little discussion and hesitation went into it.  It was clear that I was immersed in a culture that favours practice over representation, and performance over cognition, ready to go where material agency takes the engineer.

The next passages map a couple of practices popular in hacker scenes which show how such attitudes orientate a different way of engineering.

* * *

**Live coding** is programming as performance.  Live coding environments typically produce visuals to be projected onto a screen in front of an audience, sometimes accompanied by audio output from the same source.  Technically, they are source code editors which recompile the code after every statement typed, and display the results in the background.  Thus, the coder builds up the program in front of the audience, similarly to free jazz improvisations.  As in jazz, collaborations are common and systems allow the interconnection of inputs and outputs from various sources.  The source code is overlaid on the animation so that spectators can follow the evolution of the graphics and the underlying program simultaneously.

I would like to highlight three practical consequences of such an arrangement.  First, all errors, mistakes and crashes are shared with the audience.  In fact it is a commonplace amongst programmers to accept that the first version of a piece of code never runs adequately, so that it requires tuning to get it right.  However, popular discourse pictures programmers as powerful wizards who create algorithms ex nihilo.  Live coding demystifies programming by showcasing the process and not the product, and exposes the vulnerability of the programmer.  Simultaneously, it also demystifies software itself, which is shown to include plenty of glitches.

Second, the practice is obviously a critique of black boxes and a performance of the FLOSS (Free and Open Source Software) paradigm.  FLOSS advocates cite many reasons why it is beneficial if the source code of an application is available for everybody to review, run, develop and distribute.  FLOSS practices are primarily enforced by legal instruments such as licences.  Live coding makes FLOSS values explicit and inevitable through the architecture of the live coding session, where it is impossible to develop and distribute the code separately.  [Therefore, representation and performance are so tightly coupled that typing instructions is less seen as encoding a symbolic representation and more seen as a performative act in itself.]^[Programming practices used for developing robust industrial applications are in perfect contrast with live coding environments.  Programming languages used in such situations (such as C, C++ or Go) are *compiled*, which means that there has to be an explicit step where the source code is turned into executable code.  Most programming today is done in *interpreted* languages where the source code can be executed without any transformation.  Live coding takes this to the extreme by executing the source code continually, every fraction of a second.]  A corollary is that code, along with its rhythm and other manners of inscription becomes aestheticised: writing appears as an act in itself regardless of its cognitive meaning or visual consequences.

Third, programming under such constraints is less considerate than in a normal office environment.  Live programming language constructs are often syntactically terse to the point where their human understanding of is barely possible.  Moreover, the real time performance of programming means that there is no time to pause and ponder.  Therefore, once again, the programmer is not in a position to simply bend the forces of Nature to her will, but generally has to adapt and often yield to the material agency of code.  In the same way as programming can be considered a critique of the poor performative properties of human language at the same time as it is a critique of its obscurity, live coding can be considered a critique of the poor performative properties of traditional programming techniques.^[My personal experiments with the Ibniz live coding environment pointed me in this direction.  In Ibniz every conventional language construct (addition, multiplication, else, if, bitwise or, etc.) is represented by one character, and the program is compiled roughly sixty times a second, giving the illusion of continuous motion as in cinema.  When presented with the device, programmers quickly become frustrated because even after reading the manual, it is hard for them to foresee, predict, and therefore control the effects of a program.  Laypersons, however, are gleefully typing on the keyboard while exploring the combinations and intensities encountered.  What they type is not structured according to the likeness of conventional software code, it is neither random nor simply written in a human language.  They keep and add characters that seem to have interesting effects, and try out new ones without having any idea what to expect.  Therefore, the activity is historically emergent and dependent on the dialectic between human and material agency.

However, these aspects can be drawn together into a single thread by looking at them as different ways to expose professional live coders, their audience, or lay programmers to the unknown.  It is not simply that none of these people have much of an idea what comes out of a live coding session.  What is striking about such a practice – since it is in stark contrast with mainstream programming practices which resemble technological enframing rather than a ritual to reveal nature – is that it is explicitly geared towards encounters with the unknown.  In the language of *The Question Concerning Technology* one may say that live coding is a technological practice used for revealing rather than enframing [@Heidegger1993a].

Figures 1 to 4 show screen captures from live coding environments.

![Figure 1: Fluxus screencap](images/fluxus.png)

![Figure 2: Ibniz screencap #1](images/ibniz1.png)

![Figure 3: Ibniz screencap #2](images/ibniz2.png)

![Figure 4: Ibniz screencap #3](images/ibniz3.png)

* * *

**Exploratory programming** is a close relative of live coding.  It is a programming methodology taught in computer science and recommended for tackling problems that are not well understood.  For the same reason, it is ideal for learning by doing.  Since hackerspace members are not required to produce anything in particular, but often eager to learn and explore, it is not surprising that exploratory programming is popular amongst them.  Exploratory programming is most interesting when it is used to understand a particular property of the programming language itself, or even when it is loosely concentrated on a problem domain, rather than a particular real-world problem.  In any case, exploratory programming exposes the programmer to the unknown in a similar way to live coding.

In the hackerspace of Budapest (the Hungarian Autonomous Center for Knowledge, alias H.A.C.K.) one Autumn afternoon I sat with several members around the table.  One of the best programmers of the space announced happily that he is ready with paid company work, so now it is time to start another project.  After a few hours of intense work I asked him what is the new program about – what is it doing.  He answered that it is not possible to know yet.  I was astonished because he already wrote so much code, like walking without a destination.  He was building a kind of general system to programmatically parse web pages, but it was not clear yet what are the real world tasks for which it could be used more effectively than existing solutions.  This way of approaching a problem was very different from most average programming jobs where coders are paid to implement a pre-written specification, or at least work with a client to build a good product incrementally.

It was close to some academic work where ideas are tried out and practical applications can wait.  However, even academic researchers have to write a research proposal, get funding and conform to an institutionalised timeline, not to mention answer to bosses.  However, in this case there was no boss and no institutional framework, only the programmer and problem.  Conversely, the result would not be renumerated by anything other than the experience itself and perhaps the respect of coworkers.

While in most cases exploratory programming may not be so efficient as a less spontaneous software development methodology, it is surely more entertaining.  After all, it allows programmers to do what most of them enjoy the most: programming.  As the hacker saying goes: “Two hours of planning can save you two days of coding – but then again, two days of coding can save you from two hours of planning.”

* * *

**Penetration testing** is about attacking a technological system in order to find faults in it.  It can be done with malicious intent in which case it can be simply called hacking or cracking, but it can also be done under contract in order to improve security.  For instance, banks are required to hire security companies to make sure that they systems are secure and their infrastructure conforms to the relevant industry standards.  Many such companies are run by hackers.  Penetration testing can include anything from breaking into a computer network, through physical security like stealing paper documents from facilities or social engineering where the attacker talks their way to sensitive information.  However, all these approaches follow a similar way of working, and here we focus on computer networks because it is the most widespread area of expertise in hackerspaces.^[Hackerspaces often host lockpicking sport clubs and sometimes social engineering workshops, but computer security is more popular.]

My claim is that one has to accept that there is a wide field to be explored between representation and performance.  While most programmers and administrators start out by assuming that the actual performance of a program is like what is described in its specification because they have to use it as a building block in their systems, penetration testers could not even start their work without assuming that the program actually behaves differently under certain circumstances.  It is those circumstances that the penetration tester is interested in, and most often they are to be found by trying out the application in a wide variety of ways, looking at typical mistakes and known flaws in its components.  If there is a way to compromise the system, it is called a *vulnerability*.^[Serious vulnerabilities – when publically known and acknowledged – are assigned a CVE (Common Vulnerabilities and Exposures) number by the MITRE Corporation and appear in the US National Vulnerability Database.  The CVE system is funded by the National Cyber Security Division of the US Department of Homeland Security.  Anybody can request a CVE number by submitting a report of the vulnerability, and the reports are available to the general public.  Vulnerabilities are reviewed and vendors are notified of the vulnerabilities in their products.]

Vulnerabilities are effectively the (most lucrative) products of penetration testers.  Even though they are always already there in the system, hackers discover them.  While a vulnerability is a description of a weakness, eminent vulnerability reports include *exploits*.  An exploit is a short piece of code that demonstrates the vulnerability by triggering it in practice.  Therefore, exploits can be used to compromise systems in practice even by people who have only basic informatics knowledge.^[Such are called *script kiddies*, because they are using script developed by other people rather than doing their own research like a real hacker.]   Exploits are also recognised for their excange value and consequently brought and sold on the black market, or acquired legally by vendors through bug bounty programs, or even reported on public mailing list by independent researchers.

Exploits can be conceptualised as ontological theatres which extort systems into strange performances.  “No system is secure” is a mantra of hackers and each vulnerability is an additional proof of this point.  Vulnerabilities are studied by hackers both for fun and profit.  Their entertainment value comes from the fact that they achieve some unusual, often seemingly impossible task – the most prototypical being gaining administration rights to a system without knowledge of the appropriate credentials.  The root of the vulnerability are the unintended consequences of the software written by developers or the actions of the system administrators who run the vulnerable systems.  Since the consequences are unintended, most vulnerabilities are discovered by examining the performance of the systems in practice, rather than the underlying theories, even though the vulnerability may prove the theory behind the system flawed.  Therefore, a vulnerability is often theoretically impossible, and by definition unkown before its discovery.  The penetration tester have to be open to the unknown and do things that invite it to manifest itself.  There are penetration testing methodologies which are taught in universities, but searching for vulnerabilities remains a craft that requires a calling, rather than a routine prodecure than can be laid out in manuals.

An ontological theatre does not only take advantage of a particular ontological outlook in its design, but also showcases it through its performance.  As a living proof that a system does not only work as advertised, but also in other “strange” ways, an exploit points to the distance between representation and performance.  Such a performance is “strange” becuase it goes beyond – and very often against – the way given system is supposed to work.  As such it also showcases and legitimises the epistemological advantages of working in close consideration of the cybernetic ontology.

* * *

**Rapid prototyping** is a way to develop hardware without (detailed) plans.^[Rapid prototyping is also used in software engineering, but here we focus on its more popular use in hardware hacking.]  Rapid prototyping uses a dedicated repertoire of general purpose technologies which are geared towards fast cycles of iterative development rather than correctness of implementation or economy of resources.  Programmable microcontrollers (such as the open hardware Arduino board) and FPGAs (Field Programmable Gate Arrays) are as much part of its toolkit as electronic workshops in hackerspaces that stock basic components such as LEDs, stepper motors and breadboards.  Rapid prototyping focuses on making something that works as soon as possible.^[This it shares with currently fashionable *lean methodologies* in software development.]  Subsequent iterations take the artefact as a starting point, and propose changes based on the performance and potentials showed by the artefact, rather than on a pre-defined specification, road map or product sketch.

Both @Pickering2010a and @Dupuy2000a give special attention to the concept and practice of the experiment under the cybernetic regime.  They argue that one result of the shifting ontological orientation of cyberneticians was a corresponding change in what counted as an experiment.  *Modern* experiments aim for a reproducible environment where ideally only one variable is changed at any one time.  Cyberneticians, however, came to terms with a more messy experience of the world.  *In vivo* experiments happened in direct interaction with matter under real life conditions.  Interaction with what cyberneticians called *complex systems* (such as the weather, Walter Grey’s homeostatic setups or Stafford Beer’s pond) required researchers to make interventions TODO



Rapid prototyping – especially in hardware – is also highly dependent on the equipment that developers can get their hands on, since ordering new components or acquiring funding slows down the process.  On the one hand, hackerspaces traditionally include a junkyard of sorts that hackers scavenge for components.  On the other hand, hackerspaces are filled with unfinished projects that are waiting for developers to have more time or money to work on them, find or get shipped a missing component, or for others to take up interest in the idea.  Finally, it is also common to take apart actually finished projects and reuse scarce components or even whole subsystems.  These constraints can be interpreted as another form of material agency that plays its part in rapid prototyping and emerges both historically and stochastically.

Even though @Pickering2010a does not make much of these fact, there are three interesting threads that tie together the central epistemological theatres of UK cybernetics: Grey Walter’s tortoises and Ross Ashby’s homeostats.  First, they were constructed using bomb relays that were the relic of the Second World War.^[@Pickering2010a 426: “The only other reference I have found to Ashby’s source of parts for the homeostat is to the detritus of World War II: ’It has four ex RAF bomb control switch gear kits as its base, with four cubical aluminium boxes’ (3 March 1948, p. 2341).”]  Here it is worth to note that cybernetics itself was largely a product of synthesising theoretical and practical advancement made during the war.  But what is more crucial for the present argument is that the design and implementation of these artefacts was largely influenced by the technological debris of the time that was laying around in their makeshift workshops.  Second, both worked at home – Walter literally on his kitchen table and Ashby in a garden shack.  Even though they had a day job as scientists in modern research institutions, cybernetics (especially in its engineering aspect) did not lend itself easily to that context.  They had to produce a sequence of prototypes over a number of years in order to acquire official support for their (again, engineering) work.  Third, what guided the development of these prototypes was what can be termed a trial and error approach that is specific to tinkering.  However, I would prefer to call it an engineering taste, after Baumgarten’s attempts in his *Aesthetica* to rehabilitate taste as a form of knowledge.^[The *tacit knowledge* proposed in @Polanyi1958a and developed in @Polanyi1966a would be another candidate, but it is too restrictive for the kind of interactions I would like to grasp theoretically here.  Conversely, the grasp of @Sennett2009a on craftsmanship is too broad for capturing a particular milieau of engineering culture.]  As Pickering points out, the prototypes behaved in ways unexpected even by their creators, so that their development draw on a wide range of things user learned in interaction with previous prototypes, rather than mere inductive explanations.

When @Latour2008a writes about the virtues of design thinking as an amodern form of thought, he emphasises that design always starts with something which is already there.  Therefore, design is always redesign.  For Latour, this is in opposition to the Promethean hubris of modernity where the inventor is supposed to create ex nihilo.  Latour praises the careful humility of design which never starts from scratch, but shapes things attentive to the circumstances.  However, it is curious that it never occured to the author of *We Have Never Been Modern* that Prometheus only stole the fire rather than inventing it – it was already there.  Nonetheless, his description sits well with rapid prototyping, which starts from the material available at hand, strives to create a function thing as soon as possible, and tinker on from there, rejecting “’destroy it all and build something completely different’ modernism” [@Flynn2014a].

An additional factor – in hardware as well as in software – is the limited knowledge of the developers.  Hackers often venture out of their confort zone in terms of technological specialisation, but they cannot learn everything belonging to the new domain at once.  Therefore, they bring knowledges from other fields and try to valorise them in new environments.  Two rules of thumb are relevant here: “If you have a hammer, everything looks like a nail.” and “The most suitable programming language for the problem is the one you already know the best.”  Once again, such constraints do not lead to more correct or more efficient implementations, but can expand engineering culture in unexpected ways.

In hackerspaces especially, tinkering is based on personal initiative and a desire to play with technology.  This can be interpreted as a willingness to engage with material agency whereever it takes the hacker.  Arguably, the hackerspace is an organisation built for the engagement with material agency as its primary function, unlike academic institutions whose mission is also educational and corporate research departments which focus on product development.  The education, research and production in hackerspaces is a mere corollary to that – which is demonstrated in how they can mix seamlessly.  In particular, prototypes made in hackerspaces often evade modern categories of instrumentalisation.  It is not clear whether they are prototypes of personal projects, learning exercises, artworks, commercial products or activist interventions.  Hackers working on the project are often altogether uninterested in the question.  At some point the project may be abandoned, nailed to the wall of the hackerspace as an example of how to (or how *not* to) connect to specific kinds of chips to each other, but it could just as well provide the basis for a lucrative startup initiated by members.  These destinied matter little TODO








> Hacker artefacts, knowledges, practices and scenes constitute an
> alternative engineering culture that can be characterised as anti-modern
> technoscience. Stemming from a break in the 1960s cultural schock
> [@Wallerstein2004a], hackers’ relationship to technology rests on an
> approach related to the cybernetic ontology identified by @Pickering2010a
> and articulated in the sciences by cyberneticians. Such an approach
> privileges practice over representation, performance over cognition and
> adaptive encounters with the unknown over the domination of Nature. In
> short, it is informed and forged by an experience in the ontology of
> becoming.

* * *

As @DickelFerdinandPetschow2014a points out, however, hackerspaces are not merely technologically inventive – hackers are also conducting “real world experiments” with organisational structures and techniques.  Unsurprisingly, these also privilege practice over representation, performance over cognition, and adaptive encounters with the unknown.  While in the beginning of this section I related a concrete situation that was shaped by what I call anti-modern outlook rampart in hackerspaces, here I point to an entire organisational paradigm by way of rounding off the inventory of hacker practices.

**Do-ocracy** is the self-proclaimed organisational form of at least some hackerspaces, and a popular slogan in others.  It is inspired by renowned hacker Grace Hoppers’ famous phrase “It’s easier to ask forgiveness than it is to get permission.”  In the same spirit, members are encouraged to act on their own initiative without proposals or negotiations, drawing on the subsequent inspiration or disappointment of others to determine whether to go further on the same path.  For instance, new projects need not be announced but actually began to be implemented, which puts other members in a much better position to decide whether they want to join the effort.  In the same vein, changes to the very infrastructure of the hackerspace can be made arbitrarily, counting on reactions of the membership to see whether an actual improvement have been made.  Do-ocracy can be seen as an answer to cumbersome corporate bureaucracies on the one hand, and never-ending anarchist assemblies on the other hand.  As the Figures below suggest, it comes mixed with bigger or smaller doses of the ehics of care – depending how reflective are the given hacker community about forms of structural repression.

Of course, the legitimation of such

experiment

, as Curtis notes, is dangerously close to how neoclassical economists imagine a free market.


<!-- The unknown has a place in such hacker practices as *exploratory programming*, *rapid prototyping*, *live coding*, *reverse engineering*, *penetration testing* and the  -->

![Hacking Python slide](images/doocracy.png)

![NoiseBridge poster](images/doocracy-noisebridge.png)

![Labitat rule 0 poster](images/doocracy-rule0.jpg)

![“Just fucking do it” graf](images/fuckingdoit.jpg)

# Cybernetic Ontologies

In this section I would like to highlight the ethical consequences of the view of the world distilled in the cybernetic ontology.  Departing from @Pickering2010a, I  theorise the ethical consequences of the cybernetic ontology using the ontological ethics of Emmanuel Lévinas.

# Conclusion: Anti-modern TechnoScienceSociety

Finally, we are a position to ask the crucial question: how does the hackers’ world view – through practices developed on top of it – challenge modernity?

 * anti-institutions challenge institutions

\newpage

# References


